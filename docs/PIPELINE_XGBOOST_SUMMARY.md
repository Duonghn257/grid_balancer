# ğŸš€ Pipeline Dá»± Ä‘oÃ¡n Äiá»‡n TiÃªu thá»¥ vá»›i XGBoost (Cho DiCE)

## ğŸ“‹ Tá»•ng quan

Pipeline hoÃ n chá»‰nh Ä‘á»ƒ dá»± Ä‘oÃ¡n lÆ°á»£ng Ä‘iá»‡n tiÃªu thá»¥ sá»­ dá»¥ng **XGBoost** lÃ m mÃ´ hÃ¬nh duy nháº¥t, Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho viá»‡c tÃ­ch há»£p **DiCE (Diverse Counterfactual Explanations)**.

## ğŸ¯ Táº¡i sao XGBoost?

1. **Performance tá»‘t nháº¥t**: Test RÂ² = 0.9843, RMSE = 30.30 kWh
2. **TÆ°Æ¡ng thÃ­ch DiCE**: Há»— trá»£ backend='sklearn' vá»›i wrapper class
3. **Feature importance**: CÃ³ thá»ƒ giáº£i thÃ­ch Ä‘Æ°á»£c
4. **Production-ready**: Nhanh, á»•n Ä‘á»‹nh, dá»… deploy

## ğŸ”„ Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. EDA Analysis     â”‚ â†’ PhÃ¢n tÃ­ch dataset
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Data Preprocessing   â”‚ â†’ Merge, feature engineering
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Train XGBoost for DiCE       â”‚ â†’ Train vá»›i wrapper class
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Predict with XGBoost     â”‚ â†’ Dá»± Ä‘oÃ¡n lÆ°á»£ng Ä‘iá»‡n
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. DiCE Counterfactuals (TODO)  â”‚ â†’ Gá»£i Ã½ Ä‘iá»u chá»‰nh features
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Cáº¥u trÃºc Files

### Scripts chÃ­nh:
- `scripts/01_eda_analysis.py` - EDA
- `scripts/02_data_preprocessing.py` - Preprocessing
- `scripts/06_train_xgboost_for_dice.py` - **Train XGBoost cho DiCE**
- `scripts/07_predict_with_xgboost.py` - **Prediction vá»›i XGBoost**

### Output:
- `output/models/xgboost_dice.pkl` - XGBoost model
- `output/models/xgboost_wrapped_dice.pkl` - Wrapped model (cho DiCE)
- `output/models/label_encoders_dice.pkl` - Label encoders
- `output/models/model_info_dice.json` - Model info
- `output/predictions_xgboost.csv` - Káº¿t quáº£ dá»± Ä‘oÃ¡n

## ğŸš€ Quick Start

### 1. EDA Analysis
```bash
python scripts/01_eda_analysis.py
```

### 2. Data Preprocessing
```bash
python scripts/02_data_preprocessing.py
```

### 3. Train XGBoost Model
```bash
python scripts/06_train_xgboost_for_dice.py
```

**Káº¿t quáº£:**
- Model Ä‘Æ°á»£c train vÃ  lÆ°u
- Wrapper class Ä‘Æ°á»£c táº¡o sáºµn cho DiCE
- Test RÂ² ~ 0.98, RMSE ~ 30 kWh

### 4. Prediction
```bash
python scripts/07_predict_with_xgboost.py
```

**Káº¿t quáº£:**
- `output/predictions_xgboost.csv` - Káº¿t quáº£ dá»± Ä‘oÃ¡n
- Metrics: RMSE, MAE, RÂ²

## ğŸ“Š Model Performance

### XGBoost Model:
- **Train RÂ²**: 0.9939
- **Test RÂ²**: 0.9843
- **Train RMSE**: 18.32 kWh
- **Test RMSE**: 30.30 kWh
- **Test MAE**: 7.61 kWh
- **Test MAPE**: 16.88%

### So sÃ¡nh vá»›i cÃ¡c models khÃ¡c:

| Model | Test RÂ² | Test RMSE | DiCE Compatible |
|-------|---------|-----------|-----------------|
| **XGBoost** | **0.9843** | **30.30** | âœ… Yes |
| LightGBM | 0.9683 | 34.49 | âœ… Yes |
| Random Forest | 0.9702 | 33.45 | âœ… Yes |
| Linear Regression | 0.9786 | 35.38 | âœ… Yes |

## ğŸ”§ XGBoost Hyperparameters

```python
xgb_model = xgb.XGBRegressor(
    n_estimators=200,        # Sá»‘ cÃ¢y
    max_depth=8,             # Äá»™ sÃ¢u tá»‘i Ä‘a
    learning_rate=0.05,      # Tá»‘c Ä‘á»™ há»c
    subsample=0.8,           # Tá»· lá»‡ sample
    colsample_bytree=0.8,    # Tá»· lá»‡ features
    min_child_weight=3,       # Trá»ng sá»‘ tá»‘i thiá»ƒu
    random_state=42,
    n_jobs=-1,
    objective='reg:squarederror',
    eval_metric='rmse'
)
```

## ğŸ¯ Features Ä‘Æ°á»£c sá»­ dá»¥ng

### Continuous Features (28):
- `sqm`, `yearbuilt`, `numberoffloors`, `occupants`
- `airTemperature`, `cloudCoverage`, `dewTemperature`, `windSpeed`, `seaLvlPressure`, `precipDepth1HR`
- `hour`, `day_of_week`, `month`, `year`, `is_weekend`
- `hour_sin`, `hour_cos`, `day_of_week_sin`, `day_of_week_cos`, `month_sin`, `month_cos`
- `electricity_lag1`, `electricity_lag24`, `electricity_lag168`
- `electricity_rolling_mean_24h`, `electricity_rolling_std_24h`, `electricity_rolling_mean_7d`

### Categorical Features (5):
- `primaryspaceusage`, `sub_primaryspaceusage`, `site_id`, `timezone`, `season`

## ğŸ” DiCE Integration

### Wrapper Class:
Model Ä‘Ã£ Ä‘Æ°á»£c wrap trong `XGBoostWrapper` Ä‘á»ƒ:
- Tá»± Ä‘á»™ng encode categorical features
- Xá»­ lÃ½ unknown values
- TÆ°Æ¡ng thÃ­ch vá»›i DiCE backend='sklearn'

### Sá»­ dá»¥ng vá»›i DiCE:
```python
# Load wrapped model
with open('output/models/xgboost_wrapped_dice.pkl', 'rb') as f:
    model = pickle.load(f)

# Sá»­ dá»¥ng vá»›i DiCE
dice_model = dice_ml.Model(
    model=model,
    backend='sklearn',
    model_type='regressor'
)
```

## ğŸ“ˆ Use Cases

### 1. Dá»± Ä‘oÃ¡n lÆ°á»£ng Ä‘iá»‡n tiÃªu thá»¥
```python
prediction = model.predict(building_features)
# Output: 250.5 kWh
```

### 2. Kiá»ƒm tra threshold
```python
THRESHOLD = 300  # kWh
if prediction > THRESHOLD:
    # Cáº§n Ä‘iá»u chá»‰nh features
    # â†’ Sá»­ dá»¥ng DiCE Ä‘á»ƒ gá»£i Ã½
```

### 3. DiCE Counterfactuals (Sáº½ triá»ƒn khai)
```python
counterfactuals = explainer.generate_counterfactuals(
    building_features,
    desired_range=[0, THRESHOLD]
)
# â†’ Gá»£i Ã½: Giáº£m occupants, sqm, Ä‘iá»u chá»‰nh temperature
```

## âš™ï¸ TÃ¹y chá»‰nh

### Thay Ä‘á»•i sá»‘ lÆ°á»£ng buildings Ä‘á»ƒ train:
Trong `scripts/06_train_xgboost_for_dice.py`:
```python
sample_size = min(200, df['building_id'].nunique())  # Máº·c Ä‘á»‹nh 200
# Äá»ƒ train toÃ n bá»™:
sample_size = df['building_id'].nunique()
```

### Thay Ä‘á»•i hyperparameters:
Trong `scripts/06_train_xgboost_for_dice.py`, Ä‘iá»u chá»‰nh cÃ¡c tham sá»‘ cá»§a `XGBRegressor`.

## ğŸ“š TÃ i liá»‡u liÃªn quan

- [DICE_INTEGRATION.md](./DICE_INTEGRATION.md) - HÆ°á»›ng dáº«n chi tiáº¿t vá» DiCE
- [README_PIPELINE.md](./README_PIPELINE.md) - Pipeline tá»•ng quÃ¡t
- [DATA_EXPLAINATION.md](./DATA_EXPLAINATION.md) - Giáº£i thÃ­ch dataset

## ğŸ¯ Next Steps

1. âœ… Training XGBoost vá»›i wrapper class
2. âœ… Prediction pipeline
3. â³ DiCE integration script
4. â³ Visualization cho counterfactuals
5. â³ API endpoint

---

**Pipeline nÃ y Ä‘Ã£ sáºµn sÃ ng cho viá»‡c tÃ­ch há»£p DiCE!** ğŸš€
