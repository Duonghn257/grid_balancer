{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d84a2117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING PIPELINE - XGBOOST V√Ä C√ÅC M√î H√åN H·ªíI QUY\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "B∆Ø·ªöC 1: LOAD D·ªÆ LI·ªÜU\n",
      "================================================================================\n",
      "\n",
      "üìÇ ƒêang load d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω...\n",
      "‚úÖ Dataset shape: (25187366, 61)\n",
      "   - S·ªë records: 25187366\n",
      "   - S·ªë buildings: 1572\n",
      "\n",
      "üìä Features:\n",
      "   - Continuous: 10\n",
      "   - Categorical: 5\n",
      "   - Time features: 12\n",
      "   - Lag features: 6\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script 3: Training Pipeline v·ªõi XGBoost v√† c√°c m√¥ h√¨nh h·ªìi quy kh√°c\n",
    "Train v√† so s√°nh nhi·ªÅu models: XGBoost, Random Forest, LightGBM, Linear Regression\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir('..')\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING PIPELINE - XGBOOST V√Ä C√ÅC M√î H√åN H·ªíI QUY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD D·ªÆ LI·ªÜU ƒê√É X·ª¨ L√ù\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"B∆Ø·ªöC 1: LOAD D·ªÆ LI·ªÜU\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìÇ ƒêang load d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω...\")\n",
    "df = pd.read_parquet(\"./output/processed_data.parquet\")\n",
    "\n",
    "print(f\"‚úÖ Dataset shape: {df.shape}\")\n",
    "print(f\"   - S·ªë records: {len(df)}\")\n",
    "print(f\"   - S·ªë buildings: {df['building_id'].nunique()}\")\n",
    "\n",
    "# Load features info\n",
    "with open('output/features_info.json', 'r') as f:\n",
    "    features_info = json.load(f)\n",
    "\n",
    "print(f\"\\nüìä Features:\")\n",
    "print(f\"   - Continuous: {len(features_info['continuous_features'])}\")\n",
    "print(f\"   - Categorical: {len(features_info['categorical_features'])}\")\n",
    "print(f\"   - Time features: {len(features_info['time_features'])}\")\n",
    "print(f\"   - Lag features: {len(features_info['lag_features'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b1ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = min(2000, df['building_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977c7fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bull_education_Barry', 'Bull_assembly_Brandon',\n",
       "       'Cockatoo_education_Mayra', ..., 'Gator_public_Jolene',\n",
       "       'Robin_office_Gayle', 'Rat_education_Nellie'],\n",
       "      shape=(1572,), dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_buildings = np.random.choice(\n",
    "    df['building_id'].unique(), \n",
    "    size=sample_size, \n",
    "    replace=False\n",
    ")\n",
    "sample_buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8959eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>building_id</th>\n",
       "      <th>electricity_consumption</th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id_kaggle</th>\n",
       "      <th>site_id_kaggle</th>\n",
       "      <th>primaryspaceusage</th>\n",
       "      <th>sub_primaryspaceusage</th>\n",
       "      <th>sqm</th>\n",
       "      <th>sqft</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week_sin</th>\n",
       "      <th>day_of_week_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>electricity_lag1</th>\n",
       "      <th>electricity_lag24</th>\n",
       "      <th>electricity_lag168</th>\n",
       "      <th>electricity_rolling_mean_24h</th>\n",
       "      <th>electricity_rolling_std_24h</th>\n",
       "      <th>electricity_rolling_mean_7d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>Bear_assembly_Angel</td>\n",
       "      <td>237.85</td>\n",
       "      <td>Bear</td>\n",
       "      <td>602.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>22117.0</td>\n",
       "      <td>238065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.85</td>\n",
       "      <td>237.850000</td>\n",
       "      <td>237.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>Bear_assembly_Angel</td>\n",
       "      <td>221.25</td>\n",
       "      <td>Bear</td>\n",
       "      <td>602.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>22117.0</td>\n",
       "      <td>238065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>237.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.55</td>\n",
       "      <td>11.737973</td>\n",
       "      <td>229.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>Bear_assembly_Angel</td>\n",
       "      <td>222.50</td>\n",
       "      <td>Bear</td>\n",
       "      <td>602.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>22117.0</td>\n",
       "      <td>238065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>221.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.20</td>\n",
       "      <td>9.244323</td>\n",
       "      <td>227.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>Bear_assembly_Angel</td>\n",
       "      <td>221.40</td>\n",
       "      <td>Bear</td>\n",
       "      <td>602.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>22117.0</td>\n",
       "      <td>238065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>222.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.75</td>\n",
       "      <td>8.085893</td>\n",
       "      <td>225.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>Bear_assembly_Angel</td>\n",
       "      <td>224.25</td>\n",
       "      <td>Bear</td>\n",
       "      <td>602.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>22117.0</td>\n",
       "      <td>238065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>221.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.45</td>\n",
       "      <td>7.034646</td>\n",
       "      <td>225.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp          building_id  electricity_consumption site_id  \\\n",
       "0 2016-01-01 00:00:00  Bear_assembly_Angel                   237.85    Bear   \n",
       "1 2016-01-01 01:00:00  Bear_assembly_Angel                   221.25    Bear   \n",
       "2 2016-01-01 02:00:00  Bear_assembly_Angel                   222.50    Bear   \n",
       "3 2016-01-01 03:00:00  Bear_assembly_Angel                   221.40    Bear   \n",
       "4 2016-01-01 04:00:00  Bear_assembly_Angel                   224.25    Bear   \n",
       "\n",
       "   building_id_kaggle  site_id_kaggle              primaryspaceusage  \\\n",
       "0               602.0             4.0  Entertainment/public assembly   \n",
       "1               602.0             4.0  Entertainment/public assembly   \n",
       "2               602.0             4.0  Entertainment/public assembly   \n",
       "3               602.0             4.0  Entertainment/public assembly   \n",
       "4               602.0             4.0  Entertainment/public assembly   \n",
       "\n",
       "           sub_primaryspaceusage      sqm      sqft  ...  day_of_week_sin  \\\n",
       "0  Entertainment/public assembly  22117.0  238065.0  ...        -0.433884   \n",
       "1  Entertainment/public assembly  22117.0  238065.0  ...        -0.433884   \n",
       "2  Entertainment/public assembly  22117.0  238065.0  ...        -0.433884   \n",
       "3  Entertainment/public assembly  22117.0  238065.0  ...        -0.433884   \n",
       "4  Entertainment/public assembly  22117.0  238065.0  ...        -0.433884   \n",
       "\n",
       "   day_of_week_cos month_sin month_cos electricity_lag1 electricity_lag24  \\\n",
       "0        -0.900969       0.5  0.866025             0.00               0.0   \n",
       "1        -0.900969       0.5  0.866025           237.85               0.0   \n",
       "2        -0.900969       0.5  0.866025           221.25               0.0   \n",
       "3        -0.900969       0.5  0.866025           222.50               0.0   \n",
       "4        -0.900969       0.5  0.866025           221.40               0.0   \n",
       "\n",
       "  electricity_lag168 electricity_rolling_mean_24h electricity_rolling_std_24h  \\\n",
       "0                0.0                       237.85                  237.850000   \n",
       "1                0.0                       229.55                   11.737973   \n",
       "2                0.0                       227.20                    9.244323   \n",
       "3                0.0                       225.75                    8.085893   \n",
       "4                0.0                       225.45                    7.034646   \n",
       "\n",
       "  electricity_rolling_mean_7d  \n",
       "0                      237.85  \n",
       "1                      229.55  \n",
       "2                      227.20  \n",
       "3                      225.75  \n",
       "4                      225.45  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df['building_id'].isin(sample_buildings)].copy()\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a63a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(['building_id', 'timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56bd7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Features ƒë∆∞·ª£c s·ª≠ d·ª•ng:\n",
      "   - Continuous/Time/Lag: 28\n",
      "   - Categorical: 5\n"
     ]
    }
   ],
   "source": [
    "all_features = (\n",
    "    features_info['continuous_features'] + \n",
    "    features_info['time_features'] + \n",
    "    features_info['lag_features']\n",
    ")\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c features kh√¥ng c√≥ trong dataset\n",
    "all_features = [f for f in all_features if f in df_train.columns]\n",
    "categorical_features = [f for f in features_info['categorical_features'] if f in df_train.columns]\n",
    "\n",
    "print(f\"\\nüìä Features ƒë∆∞·ª£c s·ª≠ d·ª•ng:\")\n",
    "print(f\"   - Continuous/Time/Lag: {len(all_features)}\")\n",
    "print(f\"   - Categorical: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "182641a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['primaryspaceusage', 'sub_primaryspaceusage', 'site_id', 'timezone', 'season']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69cc664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqm</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>numberoffloors</th>\n",
       "      <th>occupants</th>\n",
       "      <th>airTemperature</th>\n",
       "      <th>cloudCoverage</th>\n",
       "      <th>dewTemperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>seaLvlPressure</th>\n",
       "      <th>precipDepth1HR</th>\n",
       "      <th>...</th>\n",
       "      <th>electricity_lag24</th>\n",
       "      <th>electricity_lag168</th>\n",
       "      <th>electricity_rolling_mean_24h</th>\n",
       "      <th>electricity_rolling_std_24h</th>\n",
       "      <th>electricity_rolling_mean_7d</th>\n",
       "      <th>primaryspaceusage</th>\n",
       "      <th>sub_primaryspaceusage</th>\n",
       "      <th>site_id</th>\n",
       "      <th>timezone</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22117.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.85</td>\n",
       "      <td>237.850000</td>\n",
       "      <td>237.85</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Bear</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22117.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1020.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>229.55</td>\n",
       "      <td>11.737973</td>\n",
       "      <td>229.55</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Bear</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22117.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1020.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.20</td>\n",
       "      <td>9.244323</td>\n",
       "      <td>227.20</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Bear</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22117.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1020.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.75</td>\n",
       "      <td>8.085893</td>\n",
       "      <td>225.75</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Bear</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22117.0</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.45</td>\n",
       "      <td>7.034646</td>\n",
       "      <td>225.45</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>Bear</td>\n",
       "      <td>US/Pacific</td>\n",
       "      <td>Winter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sqm  yearbuilt  numberoffloors  occupants  airTemperature  \\\n",
       "0  22117.0     1933.0             6.0        0.0             4.4   \n",
       "1  22117.0     1933.0             6.0        0.0             4.4   \n",
       "2  22117.0     1933.0             6.0        0.0             4.4   \n",
       "3  22117.0     1933.0             6.0        0.0             4.4   \n",
       "4  22117.0     1933.0             6.0        0.0             5.0   \n",
       "\n",
       "   cloudCoverage  dewTemperature  windSpeed  seaLvlPressure  precipDepth1HR  \\\n",
       "0            0.0            -2.2        0.0          1020.9             0.0   \n",
       "1            0.0            -4.4        2.1          1020.5             0.0   \n",
       "2            0.0            -6.7        2.1          1020.8             0.0   \n",
       "3            0.0            -7.8        2.6          1020.7             0.0   \n",
       "4            0.0            -9.4        0.0          1020.6             0.0   \n",
       "\n",
       "   ...  electricity_lag24  electricity_lag168  electricity_rolling_mean_24h  \\\n",
       "0  ...                0.0                 0.0                        237.85   \n",
       "1  ...                0.0                 0.0                        229.55   \n",
       "2  ...                0.0                 0.0                        227.20   \n",
       "3  ...                0.0                 0.0                        225.75   \n",
       "4  ...                0.0                 0.0                        225.45   \n",
       "\n",
       "   electricity_rolling_std_24h  electricity_rolling_mean_7d  \\\n",
       "0                   237.850000                       237.85   \n",
       "1                    11.737973                       229.55   \n",
       "2                     9.244323                       227.20   \n",
       "3                     8.085893                       225.75   \n",
       "4                     7.034646                       225.45   \n",
       "\n",
       "               primaryspaceusage          sub_primaryspaceusage  site_id  \\\n",
       "0  Entertainment/public assembly  Entertainment/public assembly     Bear   \n",
       "1  Entertainment/public assembly  Entertainment/public assembly     Bear   \n",
       "2  Entertainment/public assembly  Entertainment/public assembly     Bear   \n",
       "3  Entertainment/public assembly  Entertainment/public assembly     Bear   \n",
       "4  Entertainment/public assembly  Entertainment/public assembly     Bear   \n",
       "\n",
       "     timezone  season  \n",
       "0  US/Pacific  Winter  \n",
       "1  US/Pacific  Winter  \n",
       "2  US/Pacific  Winter  \n",
       "3  US/Pacific  Winter  \n",
       "4  US/Pacific  Winter  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_train[all_features + categorical_features].copy()\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2ee6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    237.85\n",
       "1    221.25\n",
       "2    222.50\n",
       "3    221.40\n",
       "4    224.25\n",
       "Name: electricity_consumption, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_train[features_info['target']].copy()\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2bf0367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Ki·ªÉm tra duplicate columns...\n",
      "‚ö†Ô∏è  C√≥ duplicate columns: ['season']\n",
      "   T·ªïng s·ªë columns: 33\n",
      "   Unique columns: 32\n",
      "\n",
      "üìä Ki·ªÉm tra categorical features:\n",
      "   ‚úÖ 'primaryspaceusage' l√† Series v·ªõi shape (25187366,)\n",
      "   ‚úÖ 'sub_primaryspaceusage' l√† Series v·ªõi shape (25187366,)\n",
      "   ‚úÖ 'site_id' l√† Series v·ªõi shape (25187366,)\n",
      "   ‚úÖ 'timezone' l√† Series v·ªõi shape (25187366,)\n",
      "   ‚ö†Ô∏è  'season' l√† DataFrame v·ªõi shape (25187366, 2)\n",
      "‚ö†Ô∏è  Warning: Column 'season' is a DataFrame, using first column\n",
      "\n",
      "‚úÖ ƒê√£ encode 5 categorical features\n",
      "\n",
      "üìä Ki·ªÉm tra v√† lo·∫°i b·ªè duplicate columns...\n",
      "‚ö†Ô∏è  Ph√°t hi·ªán duplicate columns: ['season']\n",
      "‚úÖ ƒê√£ lo·∫°i b·ªè duplicate columns. Shape m·ªõi: (25187366, 32)\n",
      "\n",
      "üìä ƒê·∫£m b·∫£o t·∫•t c·∫£ c·ªôt ƒë·ªÅu l√† Series 1D...\n",
      "‚úÖ X shape cu·ªëi c√πng: (25187366, 32)\n",
      "‚úÖ T·∫•t c·∫£ c·ªôt ƒë·ªÅu l√† Series 1D\n"
     ]
    }
   ],
   "source": [
    "# Ki·ªÉm tra duplicate columns\n",
    "print(\"üìä Ki·ªÉm tra duplicate columns...\")\n",
    "duplicate_cols = X.columns[X.columns.duplicated()].tolist()\n",
    "if duplicate_cols:\n",
    "    print(f\"‚ö†Ô∏è  C√≥ duplicate columns: {duplicate_cols}\")\n",
    "    print(f\"   T·ªïng s·ªë columns: {len(X.columns)}\")\n",
    "    print(f\"   Unique columns: {len(X.columns.unique())}\")\n",
    "\n",
    "# Ki·ªÉm tra t·ª´ng categorical feature\n",
    "print(f\"\\nüìä Ki·ªÉm tra categorical features:\")\n",
    "for col in categorical_features:\n",
    "    if col not in X.columns:\n",
    "        print(f\"   ‚ùå '{col}' kh√¥ng t·ªìn t·∫°i trong X\")\n",
    "    else:\n",
    "        col_data = X[col]\n",
    "        if isinstance(col_data, pd.DataFrame):\n",
    "            print(f\"   ‚ö†Ô∏è  '{col}' l√† DataFrame v·ªõi shape {col_data.shape}\")\n",
    "        elif isinstance(col_data, pd.Series):\n",
    "            print(f\"   ‚úÖ '{col}' l√† Series v·ªõi shape {col_data.shape}\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  '{col}' c√≥ type: {type(col_data)}\")\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    if col not in X.columns:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Column '{col}' not found in X, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # ƒê·∫£m b·∫£o l·∫•y Series 1D, kh√¥ng ph·∫£i DataFrame\n",
    "    col_data = X[col]\n",
    "    if isinstance(col_data, pd.DataFrame):\n",
    "        # N·∫øu l√† DataFrame (c√≥ duplicate column names), l·∫•y c·ªôt ƒë·∫ßu ti√™n\n",
    "        col_data = col_data.iloc[:, 0]\n",
    "        print(f\"‚ö†Ô∏è  Warning: Column '{col}' is a DataFrame, using first column\")\n",
    "    \n",
    "    # Convert to Series n·∫øu ch∆∞a ph·∫£i\n",
    "    if not isinstance(col_data, pd.Series):\n",
    "        col_data = pd.Series(col_data)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(col_data.astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"\\n‚úÖ ƒê√£ encode {len(label_encoders)} categorical features\")\n",
    "\n",
    "# Lo·∫°i b·ªè duplicate columns (n·∫øu c√≥)\n",
    "print(\"\\nüìä Ki·ªÉm tra v√† lo·∫°i b·ªè duplicate columns...\")\n",
    "if X.columns.duplicated().any():\n",
    "    duplicate_cols = X.columns[X.columns.duplicated()].tolist()\n",
    "    print(f\"‚ö†Ô∏è  Ph√°t hi·ªán duplicate columns: {duplicate_cols}\")\n",
    "    # Gi·ªØ l·∫°i c·ªôt ƒë·∫ßu ti√™n, lo·∫°i b·ªè c√°c c·ªôt duplicate\n",
    "    X = X.loc[:, ~X.columns.duplicated()]\n",
    "    print(f\"‚úÖ ƒê√£ lo·∫°i b·ªè duplicate columns. Shape m·ªõi: {X.shape}\")\n",
    "\n",
    "# ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c c·ªôt ƒë·ªÅu l√† Series 1D\n",
    "print(\"\\nüìä ƒê·∫£m b·∫£o t·∫•t c·∫£ c·ªôt ƒë·ªÅu l√† Series 1D...\")\n",
    "for col in X.columns:\n",
    "    col_data = X[col]\n",
    "    if isinstance(col_data, pd.DataFrame):\n",
    "        # N·∫øu l√† DataFrame, l·∫•y c·ªôt ƒë·∫ßu ti√™n\n",
    "        X[col] = col_data.iloc[:, 0]\n",
    "        print(f\"‚ö†Ô∏è  ƒê√£ s·ª≠a c·ªôt '{col}' t·ª´ DataFrame th√†nh Series\")\n",
    "    elif not isinstance(col_data, pd.Series):\n",
    "        # N·∫øu kh√¥ng ph·∫£i Series, convert\n",
    "        X[col] = pd.Series(col_data, index=X.index)\n",
    "        print(f\"‚ö†Ô∏è  ƒê√£ convert c·ªôt '{col}' th√†nh Series\")\n",
    "\n",
    "print(f\"‚úÖ X shape cu·ªëi c√πng: {X.shape}\")\n",
    "print(f\"‚úÖ T·∫•t c·∫£ c·ªôt ƒë·ªÅu l√† Series 1D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59555262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "B∆Ø·ªöC 3: CHIA TRAIN/TEST SET\n",
      "================================================================================\n",
      "‚úÖ Train set: 20149892 samples\n",
      "‚úÖ Test set: 5037474 samples\n",
      "\n",
      "   Train period: 2016-01-01 00:00:00 ƒë·∫øn 2016-09-05 15:00:00\n",
      "   Test period: 2016-09-05 16:00:00 ƒë·∫øn 2017-12-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"B∆Ø·ªöC 3: CHIA TRAIN/TEST SET\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Chia theo th·ªùi gian (80% train, 20% test)\n",
    "split_idx = int(len(df_train) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "y_train = y.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(f\"‚úÖ Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"‚úÖ Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\n   Train period: {df_train.iloc[0]['timestamp']} ƒë·∫øn {df_train.iloc[split_idx-1]['timestamp']}\")\n",
    "print(f\"   Test period: {df_train.iloc[split_idx]['timestamp']} ƒë·∫øn {df_train.iloc[-1]['timestamp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4a27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "B∆Ø·ªöC 4: TRAIN C√ÅC M√î H√åN\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4.1. Training XGBoost...\n",
      "--------------------------------------------------------------------------------\n",
      "ƒêang training...\n",
      "[0]\tvalidation_0-rmse:223.28391\tvalidation_1-rmse:230.24568\n",
      "[50]\tvalidation_0-rmse:27.04630\tvalidation_1-rmse:35.60330\n",
      "[100]\tvalidation_0-rmse:19.56809\tvalidation_1-rmse:29.64339\n",
      "[150]\tvalidation_0-rmse:18.80954\tvalidation_1-rmse:29.48399\n",
      "[199]\tvalidation_0-rmse:18.31831\tvalidation_1-rmse:30.29663\n",
      "‚úÖ XGBoost - Test RMSE: 30.30, Test R¬≤: 0.9843\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"B∆Ø·ªöC 4: TRAIN C√ÅC M√î H√åN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# ============================================================================\n",
    "# 4.1. XGBoost\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"4.1. Training XGBoost...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "print(\"ƒêang training...\")\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_xgb = xgb_model.predict(X_train)\n",
    "y_pred_test_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "train_rmse_xgb = np.sqrt(mean_squared_error(y_train, y_pred_train_xgb))\n",
    "test_rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_test_xgb))\n",
    "train_mae_xgb = mean_absolute_error(y_train, y_pred_train_xgb)\n",
    "test_mae_xgb = mean_absolute_error(y_test, y_pred_test_xgb)\n",
    "train_r2_xgb = r2_score(y_train, y_pred_train_xgb)\n",
    "test_r2_xgb = r2_score(y_test, y_pred_test_xgb)\n",
    "test_mape_xgb = mean_absolute_percentage_error(y_test, y_pred_test_xgb)\n",
    "\n",
    "models['XGBoost'] = xgb_model\n",
    "results['XGBoost'] = {\n",
    "    'train_rmse': train_rmse_xgb,\n",
    "    'test_rmse': test_rmse_xgb,\n",
    "    'train_mae': train_mae_xgb,\n",
    "    'test_mae': test_mae_xgb,\n",
    "    'train_r2': train_r2_xgb,\n",
    "    'test_r2': test_r2_xgb,\n",
    "    'test_mape': test_mape_xgb\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ XGBoost - Test RMSE: {test_rmse_xgb:.2f}, Test R¬≤: {test_r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73e2dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4.2. Training LightGBM...\n",
      "--------------------------------------------------------------------------------\n",
      "ƒêang training...\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\ttrain's rmse: 8.25511\ttrain's l2: 68.1469\ttest's rmse: 5.31647\ttest's l2: 28.2648\n",
      "[100]\ttrain's rmse: 6.62558\ttrain's l2: 43.8983\ttest's rmse: 3.56382\ttest's l2: 12.7008\n",
      "[150]\ttrain's rmse: 6.3609\ttrain's l2: 40.4611\ttest's rmse: 3.46857\ttest's l2: 12.031\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttrain's rmse: 6.27884\ttrain's l2: 39.4239\ttest's rmse: 3.44945\ttest's l2: 11.8987\n",
      "‚úÖ LightGBM - Test RMSE: 3.45, Test R¬≤: 0.9683\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4.2. LightGBM\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"4.2. Training LightGBM...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_samples=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(\"ƒêang training...\")\n",
    "lgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_names=['train', 'test'],\n",
    "    eval_metric='rmse',\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=20), lgb.log_evaluation(50)]\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_lgb = lgb_model.predict(X_train)\n",
    "y_pred_test_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "train_rmse_lgb = np.sqrt(mean_squared_error(y_train, y_pred_train_lgb))\n",
    "test_rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_test_lgb))\n",
    "train_mae_lgb = mean_absolute_error(y_train, y_pred_train_lgb)\n",
    "test_mae_lgb = mean_absolute_error(y_test, y_pred_test_lgb)\n",
    "train_r2_lgb = r2_score(y_train, y_pred_train_lgb)\n",
    "test_r2_lgb = r2_score(y_test, y_pred_test_lgb)\n",
    "test_mape_lgb = mean_absolute_percentage_error(y_test, y_pred_test_lgb)\n",
    "\n",
    "models['LightGBM'] = lgb_model\n",
    "results['LightGBM'] = {\n",
    "    'train_rmse': train_rmse_lgb,\n",
    "    'test_rmse': test_rmse_lgb,\n",
    "    'train_mae': train_mae_lgb,\n",
    "    'test_mae': test_mae_lgb,\n",
    "    'train_r2': train_r2_lgb,\n",
    "    'test_r2': test_r2_lgb,\n",
    "    'test_mape': test_mape_lgb\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ LightGBM - Test RMSE: {test_rmse_lgb:.2f}, Test R¬≤: {test_r2_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6dd9f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4.3. Training Random Forest...\n",
      "--------------------------------------------------------------------------------\n",
      "ƒêang training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Random Forest - Test RMSE: 3.35, Test R¬≤: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.8s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4.3. Random Forest\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"4.3. Training Random Forest...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"ƒêang training...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_rf = rf_model.predict(X_train)\n",
    "y_pred_test_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "train_rmse_rf = np.sqrt(mean_squared_error(y_train, y_pred_train_rf))\n",
    "test_rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_test_rf))\n",
    "train_mae_rf = mean_absolute_error(y_train, y_pred_train_rf)\n",
    "test_mae_rf = mean_absolute_error(y_test, y_pred_test_rf)\n",
    "train_r2_rf = r2_score(y_train, y_pred_train_rf)\n",
    "test_r2_rf = r2_score(y_test, y_pred_test_rf)\n",
    "test_mape_rf = mean_absolute_percentage_error(y_test, y_pred_test_rf)\n",
    "\n",
    "models['RandomForest'] = rf_model\n",
    "results['RandomForest'] = {\n",
    "    'train_rmse': train_rmse_rf,\n",
    "    'test_rmse': test_rmse_rf,\n",
    "    'train_mae': train_mae_rf,\n",
    "    'test_mae': test_mae_rf,\n",
    "    'train_r2': train_r2_rf,\n",
    "    'test_r2': test_r2_rf,\n",
    "    'test_mape': test_mape_rf\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Random Forest - Test RMSE: {test_rmse_rf:.2f}, Test R¬≤: {test_r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8275578a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4.4. Training Linear Regression (Baseline)...\n",
      "--------------------------------------------------------------------------------\n",
      "ƒêang training...\n",
      "‚úÖ Linear Regression - Test RMSE: 35.38, Test R¬≤: 0.9786\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4.4. Linear Regression (Baseline)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"4.4. Training Linear Regression (Baseline)...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu cho Linear Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "print(\"ƒêang training...\")\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_lr = lr_model.predict(X_train_scaled)\n",
    "y_pred_test_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Metrics\n",
    "train_rmse_lr = np.sqrt(mean_squared_error(y_train, y_pred_train_lr))\n",
    "test_rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_test_lr))\n",
    "train_mae_lr = mean_absolute_error(y_train, y_pred_train_lr)\n",
    "test_mae_lr = mean_absolute_error(y_test, y_pred_test_lr)\n",
    "train_r2_lr = r2_score(y_train, y_pred_train_lr)\n",
    "test_r2_lr = r2_score(y_test, y_pred_test_lr)\n",
    "test_mape_lr = mean_absolute_percentage_error(y_test, y_pred_test_lr)\n",
    "\n",
    "models['LinearRegression'] = lr_model\n",
    "models['Scaler'] = scaler  # L∆∞u scaler ƒë·ªÉ d√πng sau\n",
    "results['LinearRegression'] = {\n",
    "    'train_rmse': train_rmse_lr,\n",
    "    'test_rmse': test_rmse_lr,\n",
    "    'train_mae': train_mae_lr,\n",
    "    'test_mae': test_mae_lr,\n",
    "    'train_r2': train_r2_lr,\n",
    "    'test_r2': test_r2_lr,\n",
    "    'test_mape': test_mape_lr\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Linear Regression - Test RMSE: {test_rmse_lr:.2f}, Test R¬≤: {test_r2_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6ba657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "B∆Ø·ªöC 5: SO S√ÅNH K·∫æT QU·∫¢\n",
      "================================================================================\n",
      "\n",
      "üìä K·∫øt qu·∫£ c√°c m√¥ h√¨nh:\n",
      "================================================================================\n",
      "                  train_rmse  test_rmse  train_mae  test_mae  train_r2  test_r2  test_mape\n",
      "XGBoost              18.3183    30.2966     6.2711    7.6082    0.9939   0.9843     0.1688\n",
      "LinearRegression     38.7552    35.3788    14.7708   15.1824    0.9728   0.9786     1.9500\n",
      "\n",
      "üèÜ Model t·ªët nh·∫•t (RMSE th·∫•p nh·∫•t): XGBoost\n",
      "   - Test RMSE: 30.30\n",
      "   - Test R¬≤: 0.9843\n",
      "   - Test MAE: 7.61\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. SO S√ÅNH K·∫æT QU·∫¢\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"B∆Ø·ªöC 5: SO S√ÅNH K·∫æT QU·∫¢\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(\"\\nüìä K·∫øt qu·∫£ c√°c m√¥ h√¨nh:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string())\n",
    "\n",
    "# T√¨m model t·ªët nh·∫•t\n",
    "best_model_name = results_df['test_rmse'].idxmin()\n",
    "print(f\"\\nüèÜ Model t·ªët nh·∫•t (RMSE th·∫•p nh·∫•t): {best_model_name}\")\n",
    "print(f\"   - Test RMSE: {results_df.loc[best_model_name, 'test_rmse']:.2f}\")\n",
    "print(f\"   - Test R¬≤: {results_df.loc[best_model_name, 'test_r2']:.4f}\")\n",
    "print(f\"   - Test MAE: {results_df.loc[best_model_name, 'test_mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03005795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "B∆Ø·ªöC 6: L∆ØU MODELS V√Ä K·∫æT QU·∫¢\n",
      "================================================================================\n",
      "‚úÖ ƒê√£ l∆∞u XGBoost v√†o: output/models/xgboost.pkl\n",
      "‚úÖ ƒê√£ l∆∞u LinearRegression v√†o: output/models/linearregression.pkl\n",
      "‚úÖ ƒê√£ l∆∞u Scaler v√†o: output/models/scaler.pkl\n",
      "‚úÖ ƒê√£ l∆∞u Label Encoders v√†o: output/models/label_encoders.pkl\n",
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ so s√°nh v√†o: output/models/results_comparison.csv\n",
      "‚úÖ ƒê√£ l∆∞u th√¥ng tin model v√†o: output/models/model_info.json\n",
      "\n",
      "================================================================================\n",
      "HO√ÄN TH√ÄNH TRAINING!\n",
      "================================================================================\n",
      "‚úÖ ƒê√£ train 3 m√¥ h√¨nh\n",
      "üèÜ Model t·ªët nh·∫•t: XGBoost\n",
      "üìÅ Models ƒë√£ ƒë∆∞·ª£c l∆∞u trong: output/models/\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6. L∆ØU MODELS V√Ä K·∫æT QU·∫¢\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"B∆Ø·ªöC 6: L∆ØU MODELS V√Ä K·∫æT QU·∫¢\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "os.makedirs('output/models', exist_ok=True)\n",
    "\n",
    "# L∆∞u t·ª´ng model\n",
    "for model_name, model in models.items():\n",
    "    if model_name != 'Scaler':  # Scaler s·∫Ω l∆∞u ri√™ng\n",
    "        model_path = f\"output/models/{model_name.lower().replace(' ', '_')}.pkl\"\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u {model_name} v√†o: {model_path}\")\n",
    "\n",
    "# L∆∞u scaler\n",
    "scaler_path = \"output/models/scaler.pkl\"\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u Scaler v√†o: {scaler_path}\")\n",
    "\n",
    "# L∆∞u label encoders\n",
    "encoders_path = \"output/models/label_encoders.pkl\"\n",
    "with open(encoders_path, 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u Label Encoders v√†o: {encoders_path}\")\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "results_df.to_csv('output/models/results_comparison.csv')\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ so s√°nh v√†o: output/models/results_comparison.csv\")\n",
    "\n",
    "# L∆∞u th√¥ng tin v·ªÅ features v√† best model\n",
    "model_info = {\n",
    "    'best_model': best_model_name,\n",
    "    'features_used': all_features + categorical_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'train_size': len(X_train),\n",
    "    'test_size': len(X_test),\n",
    "    'results': results\n",
    "}\n",
    "\n",
    "with open('output/models/model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2, default=str)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u th√¥ng tin model v√†o: output/models/model_info.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"HO√ÄN TH√ÄNH TRAINING!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"‚úÖ ƒê√£ train {len(models)} m√¥ h√¨nh\")\n",
    "print(f\"üèÜ Model t·ªët nh·∫•t: {best_model_name}\")\n",
    "print(f\"üìÅ Models ƒë√£ ƒë∆∞·ª£c l∆∞u trong: output/models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787b7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
