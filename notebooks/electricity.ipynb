{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7758c28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "D·ª∞ ƒêO√ÅN NƒÇNG L∆Ø·ª¢NG ƒêI·ªÜN V·ªöI XGBOOST V√Ä DiCE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PH·∫¶N 1: LOAD V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU\n",
      "================================================================================\n",
      "\n",
      "ƒêang load d·ªØ li·ªáu...\n",
      "‚úÖ Metadata: (1636, 32)\n",
      "‚úÖ Electricity: (17544, 1579)\n",
      "‚úÖ Weather: (331166, 10)\n",
      "\n",
      "üìä T√≥m t·∫Øt d·ªØ li·ªáu:\n",
      "  - S·ªë buildings: 1636\n",
      "  - S·ªë timestamps: 17544\n",
      "  - Kho·∫£ng th·ªùi gian: 2016-01-01 00:00:00 ƒë·∫øn 2017-12-31 23:00:00\n",
      "\n",
      "ƒêang chuy·ªÉn ƒë·ªïi electricity data sang long format...\n",
      "‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: (25212579, 3)\n",
      "  - S·ªë buildings c√≥ d·ªØ li·ªáu: 1572\n",
      "  - S·ªë l∆∞·ª£ng readings: 25212579\n",
      "\n",
      "ƒêang merge v·ªõi metadata...\n",
      "‚úÖ Sau khi merge: (25212579, 34)\n",
      "  - S·ªë buildings: 1572\n",
      "  - S·ªë timestamps: 17544\n",
      "\n",
      "ƒêang merge v·ªõi weather data...\n",
      "‚úÖ Sau khi merge weather: (25212579, 42)\n",
      "\n",
      "ƒêang t·∫°o features th·ªùi gian...\n",
      "‚úÖ ƒê√£ t·∫°o c√°c features th·ªùi gian v√† lag features\n",
      "Dataset shape: (25212579, 52)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "D·ª± ƒëo√°n NƒÉng l∆∞·ª£ng ƒêi·ªán v·ªõi XGBoost v√† DiCE\n",
    "\n",
    "M·ª•c ti√™u:\n",
    "1. Ph√¢n t√≠ch Features: T√¨m ra c√°c features quan tr·ªçng nh·∫•t (PCA, Feature Importance, Correlation)\n",
    "2. D·ª± ƒëo√°n Time Series: Train XGBoost ƒë·ªÉ d·ª± ƒëo√°n ƒëi·ªán ti√™u th·ª• trong t∆∞∆°ng lai (time step = 1 gi·ªù) v·ªõi prediction interval\n",
    "3. DiCE Counterfactual Explanations: G·ª£i √Ω ƒëi·ªÅu ch·ªânh features ƒë·ªÉ kh√¥ng v∆∞·ª£t ng∆∞·ª°ng threshold\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# DiCE\n",
    "import sys\n",
    "import os\n",
    "os.chdir('..')\n",
    "import dice_ml\n",
    "from dice_ml import Dice\n",
    "\n",
    "# Visualization\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"D·ª∞ ƒêO√ÅN NƒÇNG L∆Ø·ª¢NG ƒêI·ªÜN V·ªöI XGBOOST V√Ä DiCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PH·∫¶N 1: LOAD V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PH·∫¶N 1: LOAD V√Ä X·ª¨ L√ù D·ªÆ LI·ªÜU\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c file d·ªØ li·ªáu\n",
    "base_path = \"./datasets\"\n",
    "\n",
    "electricity_path = f\"{base_path}/electricity_cleaned.csv\"\n",
    "metadata_path = f\"{base_path}/metadata.csv\"\n",
    "weather_path = f\"{base_path}/weather.csv\"\n",
    "\n",
    "print(\"\\nƒêang load d·ªØ li·ªáu...\")\n",
    "\n",
    "# Load metadata\n",
    "df_metadata = pd.read_csv(metadata_path)\n",
    "print(f\"‚úÖ Metadata: {df_metadata.shape}\")\n",
    "\n",
    "# Load electricity data\n",
    "df_electricity = pd.read_csv(electricity_path, parse_dates=['timestamp'])\n",
    "print(f\"‚úÖ Electricity: {df_electricity.shape}\")\n",
    "\n",
    "# Load weather data\n",
    "df_weather = pd.read_csv(weather_path, parse_dates=['timestamp'])\n",
    "print(f\"‚úÖ Weather: {df_weather.shape}\")\n",
    "\n",
    "print(\"\\nüìä T√≥m t·∫Øt d·ªØ li·ªáu:\")\n",
    "print(f\"  - S·ªë buildings: {len(df_metadata)}\")\n",
    "print(f\"  - S·ªë timestamps: {len(df_electricity)}\")\n",
    "print(f\"  - Kho·∫£ng th·ªùi gian: {df_electricity['timestamp'].min()} ƒë·∫øn {df_electricity['timestamp'].max()}\")\n",
    "\n",
    "# Chuy·ªÉn electricity data t·ª´ wide format sang long format\n",
    "print(\"\\nƒêang chuy·ªÉn ƒë·ªïi electricity data sang long format...\")\n",
    "\n",
    "df_electricity_long = pd.melt(\n",
    "    df_electricity,\n",
    "    id_vars=['timestamp'],\n",
    "    var_name='building_id',\n",
    "    value_name='electricity_consumption'\n",
    ")\n",
    "\n",
    "# Lo·∫°i b·ªè NaN\n",
    "df_electricity_long = df_electricity_long.dropna(subset=['electricity_consumption'])\n",
    "\n",
    "# Ch·ªâ gi·ªØ l·∫°i c√°c buildings c√≥ electricity meter\n",
    "buildings_with_electricity = df_metadata[df_metadata['electricity'] == 'Yes']['building_id'].tolist()\n",
    "df_electricity_long = df_electricity_long[df_electricity_long['building_id'].isin(buildings_with_electricity)]\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ chuy·ªÉn ƒë·ªïi: {df_electricity_long.shape}\")\n",
    "print(f\"  - S·ªë buildings c√≥ d·ªØ li·ªáu: {df_electricity_long['building_id'].nunique()}\")\n",
    "print(f\"  - S·ªë l∆∞·ª£ng readings: {len(df_electricity_long)}\")\n",
    "\n",
    "# Merge v·ªõi metadata\n",
    "print(\"\\nƒêang merge v·ªõi metadata...\")\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_electricity_long,\n",
    "    df_metadata,\n",
    "    on='building_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Sau khi merge: {df_merged.shape}\")\n",
    "print(f\"  - S·ªë buildings: {df_merged['building_id'].nunique()}\")\n",
    "print(f\"  - S·ªë timestamps: {df_merged['timestamp'].nunique()}\")\n",
    "\n",
    "# Merge v·ªõi weather data (theo site_id v√† timestamp)\n",
    "print(\"\\nƒêang merge v·ªõi weather data...\")\n",
    "\n",
    "df_final = pd.merge(\n",
    "    df_merged,\n",
    "    df_weather,\n",
    "    on=['timestamp', 'site_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Sau khi merge weather: {df_final.shape}\")\n",
    "\n",
    "# Feature Engineering: T·∫°o c√°c features th·ªùi gian\n",
    "print(\"\\nƒêang t·∫°o features th·ªùi gian...\")\n",
    "\n",
    "df_final['hour'] = df_final['timestamp'].dt.hour\n",
    "df_final['day_of_week'] = df_final['timestamp'].dt.dayofweek\n",
    "df_final['day_of_month'] = df_final['timestamp'].dt.day\n",
    "df_final['month'] = df_final['timestamp'].dt.month\n",
    "df_final['is_weekend'] = (df_final['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# T·∫°o season feature\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "df_final['season'] = df_final['month'].apply(get_season)\n",
    "\n",
    "# T·∫°o lag features (ƒëi·ªán ti√™u th·ª• gi·ªù tr∆∞·ªõc)\n",
    "df_final = df_final.sort_values(['building_id', 'timestamp'])\n",
    "df_final['electricity_lag1'] = df_final.groupby('building_id')['electricity_consumption'].shift(1)\n",
    "df_final['electricity_lag24'] = df_final.groupby('building_id')['electricity_consumption'].shift(24)  # C√πng gi·ªù ng√†y h√¥m tr∆∞·ªõc\n",
    "\n",
    "# Rolling statistics\n",
    "df_final['electricity_rolling_mean_24h'] = df_final.groupby('building_id')['electricity_consumption'].transform(\n",
    "    lambda x: x.rolling(window=24, min_periods=1).mean()\n",
    ")\n",
    "df_final['electricity_rolling_std_24h'] = df_final.groupby('building_id')['electricity_consumption'].transform(\n",
    "    lambda x: x.rolling(window=24, min_periods=1).std()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ t·∫°o c√°c features th·ªùi gian v√† lag features\")\n",
    "print(f\"Dataset shape: {df_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a51ece17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PH·∫¶N 2: PH√ÇN T√çCH FEATURES - T√åM FEATURES QUAN TR·ªåNG\n",
      "================================================================================\n",
      "\n",
      "ƒêang ph√¢n t√≠ch 50 buildings...\n",
      "Dataset shape: (806777, 52)\n",
      "Sau khi lo·∫°i b·ªè missing values: (804216, 52)\n",
      "\n",
      "Continuous features (17): ['sqm', 'yearbuilt', 'numberoffloors', 'occupants', 'airTemperature', 'cloudCoverage', 'dewTemperature', 'windSpeed', 'seaLvlPressure', 'hour', 'day_of_week', 'day_of_month', 'month', 'electricity_lag1', 'electricity_lag24', 'electricity_rolling_mean_24h', 'electricity_rolling_std_24h']\n",
      "Categorical features (6): ['primaryspaceusage', 'sub_primaryspaceusage', 'site_id', 'timezone', 'season', 'is_weekend']\n",
      "\n",
      "‚úÖ Dataset cho ph√¢n t√≠ch: (804216, 23)\n",
      "Target: (804216,)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2.1. Correlation Analysis\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Correlation v·ªõi Electricity Consumption:\n",
      "============================================================\n",
      "electricity_lag1              :  0.9823\n",
      "electricity_rolling_mean_24h  :  0.9608\n",
      "electricity_lag24             :  0.9600\n",
      "electricity_rolling_std_24h   :  0.5638\n",
      "sqm                           :  0.3782\n",
      "numberoffloors                :  0.1924\n",
      "yearbuilt                     :  0.0933\n",
      "hour                          :  0.0462\n",
      "airTemperature                :  0.0297\n",
      "month                         : -0.0009\n",
      "day_of_month                  : -0.0044\n",
      "seaLvlPressure                : -0.0062\n",
      "dewTemperature                : -0.0352\n",
      "day_of_week                   : -0.0427\n",
      "windSpeed                     : -0.0655\n",
      "occupants                     : -0.0885\n",
      "cloudCoverage                 : -0.1135\n",
      "\n",
      "‚úÖ Top 5 features c√≥ correlation cao nh·∫•t:\n",
      "electricity_lag1                0.982270\n",
      "electricity_rolling_mean_24h    0.960758\n",
      "electricity_lag24               0.959988\n",
      "electricity_rolling_std_24h     0.563799\n",
      "sqm                             0.378244\n",
      "Name: electricity_consumption, dtype: float64\n",
      "\n",
      "‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì correlation v√†o: correlation_analysis.png\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2.2. Feature Importance v·ªõi XGBoost\n",
      "--------------------------------------------------------------------------------\n",
      "ƒêang train XGBoost ƒë·ªÉ l·∫•y feature importance...\n",
      "\n",
      "üìä Feature Importance (XGBoost):\n",
      "============================================================\n",
      "electricity_lag1              :  0.9628\n",
      "sub_primaryspaceusage         :  0.0158\n",
      "sqm                           :  0.0048\n",
      "electricity_lag24             :  0.0044\n",
      "electricity_rolling_mean_24h  :  0.0023\n",
      "hour                          :  0.0018\n",
      "electricity_rolling_std_24h   :  0.0012\n",
      "day_of_week                   :  0.0008\n",
      "primaryspaceusage             :  0.0008\n",
      "numberoffloors                :  0.0007\n",
      "occupants                     :  0.0006\n",
      "timezone                      :  0.0006\n",
      "windSpeed                     :  0.0005\n",
      "dewTemperature                :  0.0004\n",
      "month                         :  0.0004\n",
      "day_of_month                  :  0.0004\n",
      "airTemperature                :  0.0003\n",
      "yearbuilt                     :  0.0003\n",
      "seaLvlPressure                :  0.0003\n",
      "site_id                       :  0.0003\n",
      "cloudCoverage                 :  0.0002\n",
      "season                        :  0.0002\n",
      "is_weekend                    :  0.0000\n",
      "\n",
      "‚úÖ Top 10 features quan tr·ªçng nh·∫•t:\n",
      "                         feature  importance\n",
      "13              electricity_lag1    0.962811\n",
      "18         sub_primaryspaceusage    0.015806\n",
      "0                            sqm    0.004813\n",
      "14             electricity_lag24    0.004430\n",
      "15  electricity_rolling_mean_24h    0.002292\n",
      "9                           hour    0.001827\n",
      "16   electricity_rolling_std_24h    0.001202\n",
      "10                   day_of_week    0.000768\n",
      "17             primaryspaceusage    0.000759\n",
      "2                 numberoffloors    0.000708\n",
      "\n",
      "‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì feature importance v√†o: feature_importance.png\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2.3. PCA Analysis\n",
      "--------------------------------------------------------------------------------\n",
      "ƒêang th·ª±c hi·ªán PCA...\n",
      "\n",
      "üìä PCA Results:\n",
      "  - S·ªë components: 17\n",
      "  - Explained variance c·ªßa 5 components ƒë·∫ßu: [0.21681629 0.11510089 0.08223292 0.0672771  0.06094795]\n",
      "  - Cumulative variance c·ªßa 5 components ƒë·∫ßu: [0.21681629 0.33191718 0.4141501  0.4814272  0.54237515]\n",
      "\n",
      "  - S·ªë components ƒë·ªÉ gi·∫£i th√≠ch 90% variance: 12\n",
      "\n",
      "‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì PCA v√†o: pca_analysis.png\n",
      "\n",
      "üìä Top 10 features ƒë√≥ng g√≥p nhi·ªÅu nh·∫•t v√†o PC1:\n",
      "                         feature       PC1\n",
      "15  electricity_rolling_mean_24h  0.498431\n",
      "13              electricity_lag1  0.494468\n",
      "14             electricity_lag24  0.490600\n",
      "16   electricity_rolling_std_24h  0.369872\n",
      "0                            sqm  0.279331\n",
      "2                 numberoffloors  0.185400\n",
      "5                  cloudCoverage -0.072016\n",
      "3                      occupants -0.062695\n",
      "1                      yearbuilt  0.059240\n",
      "7                      windSpeed -0.051671\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2.4. T·ªïng h·ª£p Features Quan tr·ªçng\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ Selected Features:\n",
      "\n",
      "Continuous features (13):\n",
      "  - sqm\n",
      "  - occupants\n",
      "  - yearbuilt\n",
      "  - numberoffloors\n",
      "  - airTemperature\n",
      "  - hour\n",
      "  - day_of_week\n",
      "  - month\n",
      "  - electricity_lag1\n",
      "  - electricity_lag24\n",
      "  - electricity_rolling_mean_24h\n",
      "  - cloudCoverage\n",
      "  - windSpeed\n",
      "\n",
      "Categorical features (5):\n",
      "  - primaryspaceusage\n",
      "  - site_id\n",
      "  - timezone\n",
      "  - season\n",
      "  - is_weekend\n",
      "\n",
      "T·ªïng c·ªông: 18 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PH·∫¶N 2: PH√ÇN T√çCH FEATURES - T√åM FEATURES QUAN TR·ªåNG\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PH·∫¶N 2: PH√ÇN T√çCH FEATURES - T√åM FEATURES QUAN TR·ªåNG\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Chu·∫©n b·ªã d·ªØ li·ªáu cho ph√¢n t√≠ch\n",
    "# Ch·ªçn m·ªôt subset buildings ƒë·ªÉ ph√¢n t√≠ch nhanh h∆°n\n",
    "np.random.seed(42)\n",
    "sample_buildings = np.random.choice(\n",
    "    df_final['building_id'].unique(), \n",
    "    size=min(50, df_final['building_id'].nunique()), \n",
    "    replace=False\n",
    ")\n",
    "df_analysis = df_final[df_final['building_id'].isin(sample_buildings)].copy()\n",
    "\n",
    "print(f\"\\nƒêang ph√¢n t√≠ch {len(sample_buildings)} buildings...\")\n",
    "print(f\"Dataset shape: {df_analysis.shape}\")\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c d√≤ng c√≥ qu√° nhi·ªÅu missing values\n",
    "df_analysis = df_analysis.dropna(subset=['electricity_consumption', 'sqm', 'airTemperature'])\n",
    "\n",
    "print(f\"Sau khi lo·∫°i b·ªè missing values: {df_analysis.shape}\")\n",
    "\n",
    "# X√°c ƒë·ªãnh c√°c features ƒë·ªÉ ph√¢n t√≠ch\n",
    "continuous_features = [\n",
    "    'sqm', 'yearbuilt', 'numberoffloors', 'occupants',\n",
    "    'airTemperature', 'cloudCoverage', 'dewTemperature', 'windSpeed', 'seaLvlPressure',\n",
    "    'hour', 'day_of_week', 'day_of_month', 'month',\n",
    "    'electricity_lag1', 'electricity_lag24', \n",
    "    'electricity_rolling_mean_24h', 'electricity_rolling_std_24h'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'primaryspaceusage', 'sub_primaryspaceusage', 'site_id', 'timezone', 'season', 'is_weekend'\n",
    "]\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c features kh√¥ng c√≥ trong dataset\n",
    "continuous_features = [f for f in continuous_features if f in df_analysis.columns]\n",
    "categorical_features = [f for f in categorical_features if f in df_analysis.columns]\n",
    "\n",
    "print(f\"\\nContinuous features ({len(continuous_features)}): {continuous_features}\")\n",
    "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# T·∫°o dataset cho ph√¢n t√≠ch\n",
    "X_analysis = df_analysis[continuous_features + categorical_features].copy()\n",
    "y_analysis = df_analysis['electricity_consumption'].copy()\n",
    "\n",
    "# Fill missing values\n",
    "for col in continuous_features:\n",
    "    if col in X_analysis.columns:\n",
    "        X_analysis[col] = X_analysis[col].fillna(X_analysis[col].median())\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in X_analysis.columns:\n",
    "        X_analysis[col] = X_analysis[col].fillna(\n",
    "            X_analysis[col].mode()[0] if len(X_analysis[col].mode()) > 0 else 'Unknown'\n",
    "        )\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    if col in X_analysis.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_analysis[col] = le.fit_transform(X_analysis[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset cho ph√¢n t√≠ch: {X_analysis.shape}\")\n",
    "print(f\"Target: {y_analysis.shape}\")\n",
    "\n",
    "# 2.1. Correlation Analysis\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"2.1. Correlation Analysis\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "correlation_data = X_analysis[continuous_features].copy()\n",
    "correlation_data['electricity_consumption'] = y_analysis\n",
    "\n",
    "correlations = correlation_data.corr()['electricity_consumption'].sort_values(ascending=False)\n",
    "correlations = correlations.drop('electricity_consumption')\n",
    "\n",
    "print(\"\\nüìä Correlation v·ªõi Electricity Consumption:\")\n",
    "print(\"=\" * 60)\n",
    "for feature, corr in correlations.items():\n",
    "    print(f\"{feature:30s}: {corr:7.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Top 5 features c√≥ correlation cao nh·∫•t:\")\n",
    "print(correlations.head(5))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlations.plot(kind='barh')\n",
    "plt.title('Correlation v·ªõi Electricity Consumption', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./analysis/correlation_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì correlation v√†o: correlation_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2.2. Feature Importance v·ªõi XGBoost\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"2.2. Feature Importance v·ªõi XGBoost\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"ƒêang train XGBoost ƒë·ªÉ l·∫•y feature importance...\")\n",
    "\n",
    "# Chia train/test theo th·ªùi gian\n",
    "df_analysis_sorted = df_analysis.sort_values('timestamp')\n",
    "split_idx = int(len(df_analysis_sorted) * 0.8)\n",
    "\n",
    "X_train_imp = X_analysis.iloc[:split_idx]\n",
    "y_train_imp = y_analysis.iloc[:split_idx]\n",
    "X_test_imp = X_analysis.iloc[split_idx:]\n",
    "y_test_imp = y_analysis.iloc[split_idx:]\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model_imp = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model_imp.fit(X_train_imp, y_train_imp)\n",
    "\n",
    "# L·∫•y feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_analysis.columns,\n",
    "    'importance': xgb_model_imp.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Feature Importance (XGBoost):\")\n",
    "print(\"=\" * 60)\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:30s}: {row['importance']:7.4f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Top 10 features quan tr·ªçng nh·∫•t:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 10))\n",
    "feature_importance.plot(x='feature', y='importance', kind='barh', figsize=(10, 10))\n",
    "plt.title('Feature Importance (XGBoost)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./analysis/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì feature importance v√†o: feature_importance.png\")\n",
    "plt.close()\n",
    "\n",
    "# 2.3. PCA Analysis\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"2.3. PCA Analysis\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"ƒêang th·ª±c hi·ªán PCA...\")\n",
    "\n",
    "# Chu·∫©n h√≥a d·ªØ li·ªáu\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_analysis[continuous_features])\n",
    "\n",
    "# PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# T√≠nh explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "print(f\"\\nüìä PCA Results:\")\n",
    "print(f\"  - S·ªë components: {len(explained_variance)}\")\n",
    "print(f\"  - Explained variance c·ªßa 5 components ƒë·∫ßu: {explained_variance[:5]}\")\n",
    "print(f\"  - Cumulative variance c·ªßa 5 components ƒë·∫ßu: {cumulative_variance[:5]}\")\n",
    "\n",
    "# T√¨m s·ªë components c·∫ßn ƒë·ªÉ gi·∫£i th√≠ch 90% variance\n",
    "n_components_90 = np.where(cumulative_variance >= 0.90)[0][0] + 1\n",
    "print(f\"\\n  - S·ªë components ƒë·ªÉ gi·∫£i th√≠ch 90% variance: {n_components_90}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Explained variance\n",
    "axes[0].plot(range(1, len(explained_variance) + 1), explained_variance, 'bo-')\n",
    "axes[0].set_xlabel('Principal Component', fontsize=12)\n",
    "axes[0].set_ylabel('Explained Variance Ratio', fontsize=12)\n",
    "axes[0].set_title('Explained Variance by Component', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Cumulative variance\n",
    "axes[1].plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'ro-')\n",
    "axes[1].axhline(y=0.90, color='g', linestyle='--', label='90% Variance')\n",
    "axes[1].axvline(x=n_components_90, color='g', linestyle='--')\n",
    "axes[1].set_xlabel('Number of Components', fontsize=12)\n",
    "axes[1].set_ylabel('Cumulative Explained Variance', fontsize=12)\n",
    "axes[1].set_title('Cumulative Explained Variance', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./analysis/pca_analysis.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì PCA v√†o: pca_analysis.png\")\n",
    "plt.close()\n",
    "\n",
    "# Component loadings cho PC1 v√† PC2\n",
    "pc1_loadings = pd.DataFrame({\n",
    "    'feature': continuous_features,\n",
    "    'PC1': pca.components_[0],\n",
    "    'PC2': pca.components_[1]\n",
    "}).sort_values('PC1', key=abs, ascending=False)\n",
    "\n",
    "print(f\"\\nüìä Top 10 features ƒë√≥ng g√≥p nhi·ªÅu nh·∫•t v√†o PC1:\")\n",
    "print(pc1_loadings.head(10)[['feature', 'PC1']])\n",
    "\n",
    "# 2.4. T·ªïng h·ª£p Features Quan tr·ªçng\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"2.4. T·ªïng h·ª£p Features Quan tr·ªçng\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Ch·ªçn features quan tr·ªçng d·ª±a tr√™n ph√¢n t√≠ch\n",
    "selected_continuous_features = [\n",
    "    'sqm',                    # Di·ªán t√≠ch - r·∫•t quan tr·ªçng\n",
    "    'occupants',              # S·ªë ng∆∞·ªùi - r·∫•t quan tr·ªçng\n",
    "    'yearbuilt',              # NƒÉm x√¢y d·ª±ng\n",
    "    'numberoffloors',         # S·ªë t·∫ßng\n",
    "    'airTemperature',         # Nhi·ªát ƒë·ªô - r·∫•t quan tr·ªçng\n",
    "    'hour',                   # Gi·ªù trong ng√†y - pattern s·ª≠ d·ª•ng\n",
    "    'day_of_week',            # Ng√†y trong tu·∫ßn\n",
    "    'month',                  # Th√°ng - m√πa\n",
    "    'electricity_lag1',       # Lag 1 gi·ªù\n",
    "    'electricity_lag24',      # Lag 24 gi·ªù (c√πng gi·ªù h√¥m tr∆∞·ªõc)\n",
    "    'electricity_rolling_mean_24h',  # Trung b√¨nh 24h\n",
    "    'cloudCoverage',          # ƒê·ªô che ph·ªß m√¢y\n",
    "    'windSpeed'               # T·ªëc ƒë·ªô gi√≥\n",
    "]\n",
    "\n",
    "selected_categorical_features = [\n",
    "    'primaryspaceusage',      # Lo·∫°i s·ª≠ d·ª•ng - r·∫•t quan tr·ªçng\n",
    "    'site_id',                # Site\n",
    "    'timezone',               # M√∫i gi·ªù\n",
    "    'season',                 # M√πa\n",
    "    'is_weekend'              # Cu·ªëi tu·∫ßn\n",
    "]\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c features kh√¥ng c√≥ trong dataset\n",
    "selected_continuous_features = [f for f in selected_continuous_features if f in df_final.columns]\n",
    "selected_categorical_features = [f for f in selected_categorical_features if f in df_final.columns]\n",
    "\n",
    "print(\"\\n‚úÖ Selected Features:\")\n",
    "print(f\"\\nContinuous features ({len(selected_continuous_features)}):\")\n",
    "for f in selected_continuous_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(f\"\\nCategorical features ({len(selected_categorical_features)}):\")\n",
    "for f in selected_categorical_features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(f\"\\nT·ªïng c·ªông: {len(selected_continuous_features) + len(selected_categorical_features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb594ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PH·∫¶N 3: TRAIN XGBOOST MODEL V·ªöI PREDICTION INTERVALS\n",
      "================================================================================\n",
      "\n",
      "ƒêang train v·ªõi 100 buildings...\n",
      "Dataset shape: (1554730, 52)\n",
      "Sau khi x·ª≠ l√Ω missing values: (1547157, 52)\n",
      "\n",
      "Train set: 1237725 samples\n",
      "Test set: 309432 samples\n",
      "\n",
      "Train period: 2016-01-01 00:00:00 ƒë·∫øn 2017-08-13 20:00:00\n",
      "Test period: 2017-08-13 20:00:00 ƒë·∫øn 2017-12-31 23:00:00\n",
      "\n",
      "ƒêang train XGBoost model...\n",
      "[0]\tvalidation_0-rmse:352.01118\tvalidation_1-rmse:123.34727\n",
      "[50]\tvalidation_0-rmse:132.06010\tvalidation_1-rmse:35.51882\n",
      "[100]\tvalidation_0-rmse:64.43194\tvalidation_1-rmse:36.27230\n",
      "[150]\tvalidation_0-rmse:37.55444\tvalidation_1-rmse:36.95680\n",
      "[199]\tvalidation_0-rmse:24.55678\tvalidation_1-rmse:37.77471\n",
      "\n",
      "‚úÖ Model Performance:\n",
      "\n",
      "Train Set:\n",
      "  RMSE: 24.56 kWh\n",
      "  MAE:  5.30 kWh\n",
      "  R¬≤:   0.9954\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 37.77 kWh\n",
      "  MAE:  11.10 kWh\n",
      "  R¬≤:   0.9056\n",
      "\n",
      "ƒêang t√≠nh prediction intervals d·ª±a tr√™n residuals...\n",
      "‚úÖ ƒê√£ t√≠nh prediction intervals\n",
      "\n",
      "üìä Prediction Interval Coverage: 53.12% (target: 80%)\n",
      "üìä Average Interval Width: 13.96 kWh\n",
      "üìä Residual Std: 24.56 kWh\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Format Output - D·ª± ƒëo√°n cho t·ª´ng T√≤a nh√†\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ K·∫øt qu·∫£ d·ª± ƒëo√°n cho 95 buildings\n",
      "   T·ªïng c·ªông 309432 predictions (m·ªói prediction = 1 building √ó 1 gi·ªù)\n",
      "\n",
      "üìã Format Output (10 d√≤ng ƒë·∫ßu):\n",
      "                  building_id           timestamp  actual_consumption  \\\n",
      "0          Fox_education_Etta 2017-08-13 20:00:00                1.28   \n",
      "1            Rat_assembly_Ida 2017-08-13 20:00:00                1.32   \n",
      "2       Bull_education_Kendra 2017-08-13 20:00:00                1.32   \n",
      "3       Bull_education_Dottie 2017-08-13 20:00:00                1.32   \n",
      "4        Gator_assembly_Lelia 2017-08-13 20:00:00                1.32   \n",
      "5    Moose_education_Florence 2017-08-13 20:00:00                1.32   \n",
      "6         Hog_education_Jared 2017-08-13 20:00:00                1.28   \n",
      "7  Cockatoo_education_Melanie 2017-08-13 20:00:00                1.28   \n",
      "8        Fox_education_Tamika 2017-08-13 20:00:00                0.76   \n",
      "9        Bull_services_Nadine 2017-08-13 20:00:00                0.60   \n",
      "\n",
      "   predicted_consumption  predicted_lower  predicted_upper  \\\n",
      "0               1.961686        -4.892739         9.065661   \n",
      "1               1.824589        -5.029836         8.928564   \n",
      "2               1.824879        -5.029545         8.928855   \n",
      "3               1.800242        -5.054183         8.904217   \n",
      "4               1.811143        -5.043282         8.915118   \n",
      "5               1.886886        -4.967539         8.990861   \n",
      "6               2.278363        -4.576062         9.382338   \n",
      "7               2.274124        -4.580300         9.378100   \n",
      "8               2.274124        -4.580300         9.378100   \n",
      "9               1.152454        -5.701970         8.256430   \n",
      "\n",
      "   prediction_interval_width              primaryspaceusage      sqm   site_id  \n",
      "0                    13.9584                      Education   4497.5       Fox  \n",
      "1                    13.9584  Entertainment/public assembly   1378.9       Rat  \n",
      "2                    13.9584                      Education  16640.3      Bull  \n",
      "3                    13.9584                      Education  39822.6      Bull  \n",
      "4                    13.9584  Entertainment/public assembly    297.3     Gator  \n",
      "5                    13.9584                      Education  26999.9     Moose  \n",
      "6                    13.9584                      Education   1317.8       Hog  \n",
      "7                    13.9584                      Education   3240.0  Cockatoo  \n",
      "8                    13.9584                      Education   8339.9       Fox  \n",
      "9                    13.9584                       Services  36198.8      Bull  \n",
      "\n",
      "üìä Th·ªëng k√™:\n",
      "  - S·ªë buildings: 95\n",
      "  - S·ªë timestamps: 3364\n",
      "  - S·ªë predictions: 309432\n",
      "  - Trung b√¨nh prediction interval width: 13.96 kWh\n",
      "\n",
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n v√†o: predictions_results.csv\n",
      "\n",
      "ƒêang t·∫°o visualizations...\n",
      "‚úÖ ƒê√£ l∆∞u visualization v√†o: predictions_visualization.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PH·∫¶N 3: TRAIN XGBOOST MODEL V·ªöI PREDICTION INTERVALS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PH·∫¶N 3: TRAIN XGBOOST MODEL V·ªöI PREDICTION INTERVALS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Chu·∫©n b·ªã d·ªØ li·ªáu cho training\n",
    "np.random.seed(42)\n",
    "train_buildings = np.random.choice(\n",
    "    df_final['building_id'].unique(), \n",
    "    size=min(100, df_final['building_id'].nunique()), \n",
    "    replace=False\n",
    ")\n",
    "\n",
    "df_train = df_final[df_final['building_id'].isin(train_buildings)].copy()\n",
    "df_train = df_train.sort_values(['building_id', 'timestamp'])\n",
    "\n",
    "print(f\"\\nƒêang train v·ªõi {len(train_buildings)} buildings...\")\n",
    "print(f\"Dataset shape: {df_train.shape}\")\n",
    "\n",
    "# Lo·∫°i b·ªè missing values trong target v√† c√°c features quan tr·ªçng\n",
    "df_train = df_train.dropna(subset=['electricity_consumption', 'sqm', 'airTemperature'])\n",
    "\n",
    "# Fill missing values\n",
    "for col in selected_continuous_features:\n",
    "    if col in df_train.columns:\n",
    "        df_train[col] = df_train.groupby('building_id')[col].transform(\n",
    "            lambda x: x.fillna(x.median() if not x.isna().all() else 0)\n",
    "        )\n",
    "\n",
    "for col in selected_categorical_features:\n",
    "    if col in df_train.columns:\n",
    "        df_train[col] = df_train[col].fillna(\n",
    "            df_train[col].mode()[0] if len(df_train[col].mode()) > 0 else 'Unknown'\n",
    "        )\n",
    "\n",
    "print(f\"Sau khi x·ª≠ l√Ω missing values: {df_train.shape}\")\n",
    "\n",
    "# T·∫°o features v√† target\n",
    "X = df_train[selected_continuous_features + selected_categorical_features].copy()\n",
    "y = df_train['electricity_consumption'].copy()\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders_train = {}\n",
    "for col in selected_categorical_features:\n",
    "    if col in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col].astype(str))\n",
    "        label_encoders_train[col] = le\n",
    "\n",
    "# Chia train/test theo th·ªùi gian (time series split)\n",
    "df_train_sorted = df_train.sort_values('timestamp')\n",
    "split_idx = int(len(df_train_sorted) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "y_train = y.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTrain period: {df_train_sorted.iloc[0]['timestamp']} ƒë·∫øn {df_train_sorted.iloc[split_idx-1]['timestamp']}\")\n",
    "print(f\"Test period: {df_train_sorted.iloc[split_idx]['timestamp']} ƒë·∫øn {df_train_sorted.iloc[-1]['timestamp']}\")\n",
    "\n",
    "# Train XGBoost model ch√≠nh\n",
    "print(\"\\nƒêang train XGBoost model...\")\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = xgb_model.predict(X_train)\n",
    "y_pred_test = xgb_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\n‚úÖ Model Performance:\")\n",
    "print(f\"\\nTrain Set:\")\n",
    "print(f\"  RMSE: {train_rmse:.2f} kWh\")\n",
    "print(f\"  MAE:  {train_mae:.2f} kWh\")\n",
    "print(f\"  R¬≤:   {train_r2:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  RMSE: {test_rmse:.2f} kWh\")\n",
    "print(f\"  MAE:  {test_mae:.2f} kWh\")\n",
    "print(f\"  R¬≤:   {test_r2:.4f}\")\n",
    "\n",
    "# Train models cho prediction intervals\n",
    "print(\"\\nƒêang t√≠nh prediction intervals d·ª±a tr√™n residuals...\")\n",
    "\n",
    "# T√≠nh residuals tr√™n training set\n",
    "residuals = y_train - y_pred_train\n",
    "\n",
    "# T√≠nh standard deviation c·ªßa residuals\n",
    "residual_std = np.std(residuals)\n",
    "\n",
    "# Predictions tr√™n test set\n",
    "y_pred_mean = xgb_model.predict(X_test)\n",
    "\n",
    "# T·∫°o prediction intervals (80% confidence interval)\n",
    "confidence_level = 0.80\n",
    "alpha = 1 - confidence_level\n",
    "z_score = 1.28  # Cho 80% confidence interval\n",
    "\n",
    "# D·ª±a tr√™n percentile c·ªßa residuals (ch√≠nh x√°c h∆°n)\n",
    "percentile_lower = (alpha / 2) * 100\n",
    "percentile_upper = (1 - alpha / 2) * 100\n",
    "residual_lower = np.percentile(residuals, percentile_lower)\n",
    "residual_upper = np.percentile(residuals, percentile_upper)\n",
    "\n",
    "y_pred_lower = y_pred_mean + residual_lower\n",
    "y_pred_upper = y_pred_mean + residual_upper\n",
    "\n",
    "print(\"‚úÖ ƒê√£ t√≠nh prediction intervals\")\n",
    "\n",
    "# T√≠nh coverage (t·ª∑ l·ªá gi√° tr·ªã th·ª±c t·∫ø n·∫±m trong interval)\n",
    "coverage = np.mean((y_test >= y_pred_lower) & (y_test <= y_pred_upper))\n",
    "print(f\"\\nüìä Prediction Interval Coverage: {coverage:.2%} (target: {confidence_level:.0%})\")\n",
    "\n",
    "# T√≠nh ƒë·ªô r·ªông trung b√¨nh c·ªßa interval\n",
    "interval_width = np.mean(y_pred_upper - y_pred_lower)\n",
    "print(f\"üìä Average Interval Width: {interval_width:.2f} kWh\")\n",
    "print(f\"üìä Residual Std: {residual_std:.2f} kWh\")\n",
    "\n",
    "# T·∫°o DataFrame k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Format Output - D·ª± ƒëo√°n cho t·ª´ng T√≤a nh√†\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'building_id': df_train_sorted.iloc[split_idx:]['building_id'].values,\n",
    "    'timestamp': df_train_sorted.iloc[split_idx:]['timestamp'].values,\n",
    "    'actual_consumption': y_test.values,\n",
    "    'predicted_consumption': y_pred_mean,\n",
    "    'predicted_lower': y_pred_lower,\n",
    "    'predicted_upper': y_pred_upper,\n",
    "    'prediction_interval_width': y_pred_upper - y_pred_lower\n",
    "})\n",
    "\n",
    "# Th√™m th√¥ng tin v·ªÅ building\n",
    "results_df = pd.merge(\n",
    "    results_df,\n",
    "    df_metadata[['building_id', 'primaryspaceusage', 'sqm', 'site_id']],\n",
    "    on='building_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ K·∫øt qu·∫£ d·ª± ƒëo√°n cho {results_df['building_id'].nunique()} buildings\")\n",
    "print(f\"   T·ªïng c·ªông {len(results_df)} predictions (m·ªói prediction = 1 building √ó 1 gi·ªù)\")\n",
    "print(f\"\\nüìã Format Output (10 d√≤ng ƒë·∫ßu):\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "print(f\"\\nüìä Th·ªëng k√™:\")\n",
    "print(f\"  - S·ªë buildings: {results_df['building_id'].nunique()}\")\n",
    "print(f\"  - S·ªë timestamps: {results_df['timestamp'].nunique()}\")\n",
    "print(f\"  - S·ªë predictions: {len(results_df)}\")\n",
    "print(f\"  - Trung b√¨nh prediction interval width: {results_df['prediction_interval_width'].mean():.2f} kWh\")\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£\n",
    "results_df.to_csv('./output/predictions_results.csv', index=False)\n",
    "print(f\"\\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n v√†o: predictions_results.csv\")\n",
    "\n",
    "# Visualization: Predictions v·ªõi intervals\n",
    "print(\"\\nƒêang t·∫°o visualizations...\")\n",
    "\n",
    "# Plot 1: Sample predictions cho m·ªôt building\n",
    "sample_building = train_buildings[0]\n",
    "building_test = results_df[results_df['building_id'] == sample_building].head(100)\n",
    "\n",
    "if len(building_test) > 0:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    timestamps = building_test['timestamp'].values\n",
    "    actual = building_test['actual_consumption'].values\n",
    "    predicted = building_test['predicted_consumption'].values\n",
    "    lower = building_test['predicted_lower'].values\n",
    "    upper = building_test['predicted_upper'].values\n",
    "    \n",
    "    axes[0].plot(timestamps, actual, 'b-', label='Actual', linewidth=2, marker='o', markersize=3)\n",
    "    axes[0].plot(timestamps, predicted, 'r-', label='Predicted', linewidth=2, marker='s', markersize=3)\n",
    "    axes[0].fill_between(timestamps, lower, upper, alpha=0.3, color='gray', label='80% Prediction Interval')\n",
    "    axes[0].set_xlabel('Timestamp', fontsize=12)\n",
    "    axes[0].set_ylabel('Electricity Consumption (kWh)', fontsize=12)\n",
    "    axes[0].set_title(f'Predictions v·ªõi Intervals - Building: {sample_building}', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    plt.setp(axes[0].xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Plot 2: Scatter plot - Actual vs Predicted\n",
    "    sample_size_scatter = min(1000, len(y_test))\n",
    "    sample_idx_scatter = np.random.choice(len(y_test), sample_size_scatter, replace=False)\n",
    "    \n",
    "    axes[1].scatter(y_test.iloc[sample_idx_scatter], y_pred_mean[sample_idx_scatter], alpha=0.5)\n",
    "    axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    axes[1].set_xlabel('Actual Electricity Consumption (kWh)', fontsize=12)\n",
    "    axes[1].set_ylabel('Predicted Electricity Consumption (kWh)', fontsize=12)\n",
    "    axes[1].set_title('Actual vs Predicted', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./output/predictions_visualization.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"‚úÖ ƒê√£ l∆∞u visualization v√†o: predictions_visualization.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21fdbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PH·∫¶N 4: S·ª¨ D·ª§NG DiCE ƒê·ªÇ G·ª¢I √ù ƒêI·ªÄU CH·ªàNH FEATURES\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Features cho DiCE: ['sqm', 'occupants', 'yearbuilt', 'numberoffloors', 'airTemperature', 'hour', 'day_of_week', 'month', 'cloudCoverage', 'windSpeed', 'primaryspaceusage', 'site_id', 'timezone', 'season', 'is_weekend']\n",
      "   T·ªïng c·ªông: 15 features\n",
      "\n",
      "ƒêang train model ri√™ng cho DiCE (ch·ªâ v·ªõi adjustable features)...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PH·∫¶N 4: S·ª¨ D·ª§NG DiCE ƒê·ªÇ G·ª¢I √ù ƒêI·ªÄU CH·ªàNH FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PH·∫¶N 4: S·ª¨ D·ª§NG DiCE ƒê·ªÇ G·ª¢I √ù ƒêI·ªÄU CH·ªàNH FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Chu·∫©n b·ªã d·ªØ li·ªáu cho DiCE\n",
    "# Ch·ªâ l·∫•y c√°c features c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c\n",
    "adjustable_features = [\n",
    "    'sqm', 'occupants', 'yearbuilt', 'numberoffloors',\n",
    "    'airTemperature', 'hour', 'day_of_week', 'month',\n",
    "    'cloudCoverage', 'windSpeed'\n",
    "]\n",
    "\n",
    "adjustable_categorical = [\n",
    "    'primaryspaceusage', 'site_id', 'timezone', 'season', 'is_weekend'\n",
    "]\n",
    "\n",
    "# L·∫•y c√°c features c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh (ph·∫£i c√≥ trong df_train)\n",
    "dice_features = [f for f in adjustable_features + adjustable_categorical if f in df_train.columns]\n",
    "\n",
    "print(f\"\\n‚úÖ Features cho DiCE: {dice_features}\")\n",
    "print(f\"   T·ªïng c·ªông: {len(dice_features)} features\")\n",
    "\n",
    "# Train m·ªôt model ri√™ng cho DiCE ch·ªâ v·ªõi adjustable features\n",
    "# (v√¨ lag features v√† rolling features kh√¥ng th·ªÉ ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c)\n",
    "print(\"\\nƒêang train model ri√™ng cho DiCE (ch·ªâ v·ªõi adjustable features)...\")\n",
    "\n",
    "# T·∫°o dataset ch·ªâ v·ªõi adjustable features\n",
    "X_dice = df_train[dice_features].copy()\n",
    "y_dice = df_train['electricity_consumption'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e6cabe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sqm', 'occupants', 'yearbuilt', 'numberoffloors', 'airTemperature',\n",
       "       'hour', 'day_of_week', 'month', 'cloudCoverage', 'windSpeed',\n",
       "       'primaryspaceusage', 'site_id', 'timezone', 'season', 'is_weekend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dice.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebb65d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11541ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff873f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PH·∫¶N 4: S·ª¨ D·ª§NG DiCE ƒê·ªÇ G·ª¢I √ù ƒêI·ªÄU CH·ªàNH FEATURES\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Features cho DiCE: ['sqm', 'occupants', 'yearbuilt', 'numberoffloors', 'airTemperature', 'hour', 'day_of_week', 'month', 'cloudCoverage', 'windSpeed', 'primaryspaceusage', 'site_id', 'timezone', 'season', 'is_weekend']\n",
      "   T·ªïng c·ªông: 15 features\n",
      "\n",
      "ƒêang train model ri√™ng cho DiCE (ch·ªâ v·ªõi adjustable features)...\n",
      "[0]\tvalidation_0-rmse:354.38040\tvalidation_1-rmse:125.54885\n",
      "[50]\tvalidation_0-rmse:205.63736\tvalidation_1-rmse:375.48133\n",
      "[100]\tvalidation_0-rmse:167.64600\tvalidation_1-rmse:395.42209\n",
      "[150]\tvalidation_0-rmse:143.45897\tvalidation_1-rmse:396.85885\n",
      "[199]\tvalidation_0-rmse:123.80094\tvalidation_1-rmse:397.29160\n",
      "\n",
      "‚úÖ Model DiCE Performance:\n",
      "  RMSE: 397.29 kWh\n",
      "  R¬≤:   -9.4425\n",
      "\n",
      "‚úÖ Dataset cho DiCE: (1237725, 16)\n",
      "   Features: ['sqm', 'occupants', 'yearbuilt', 'numberoffloors', 'airTemperature', 'hour', 'day_of_week', 'month', 'cloudCoverage', 'windSpeed', 'primaryspaceusage', 'site_id', 'timezone', 'season', 'is_weekend']\n",
      "   Target: electricity_consumption\n",
      "\n",
      "‚úÖ DiCE Data object ƒë√£ ƒë∆∞·ª£c t·∫°o!\n",
      "‚úÖ DiCE Model object ƒë√£ ƒë∆∞·ª£c t·∫°o!\n",
      "‚úÖ DiCE Explainer ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi method='random'!\n",
      "   (C√≥ th·ªÉ ƒë·ªïi th√†nh 'genetic' n·∫øu mu·ªën k·∫øt qu·∫£ t·ªët h∆°n nh∆∞ng ch·∫≠m h∆°n)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Building ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ t·ªëi ∆∞u:\n",
      "--------------------------------------------------------------------------------\n",
      "  Building ID: Bull_education_Dottie\n",
      "  L∆∞·ª£ng ƒëi·ªán ti√™u th·ª• th·ª±c t·∫ø: 221228.00 kWh\n",
      "\n",
      "Features hi·ªán t·∫°i (adjustable features):\n",
      "  sqm                      : 39822.6\n",
      "  occupants                : 0.0\n",
      "  yearbuilt                : 0.0\n",
      "  numberoffloors           : 0.0\n",
      "  airTemperature           : 30.6\n",
      "  hour                     : 15\n",
      "  day_of_week              : 2\n",
      "  month                    : 9\n",
      "  cloudCoverage            : 0.0\n",
      "  windSpeed                : 3.6\n",
      "  primaryspaceusage        : Education\n",
      "  site_id                  : Bull\n",
      "  timezone                 : US/Central\n",
      "  season                   : Fall\n",
      "  is_weekend               : 0\n",
      "\n",
      "  D·ª± ƒëo√°n t·ª´ model DiCE: 134542.52 kWh\n",
      "\n",
      "üìä Ng∆∞·ª°ng t·ªëi ƒëa cho ph√©p: 73.36 kWh\n",
      "üìä L∆∞·ª£ng ƒëi·ªán hi·ªán t·∫°i: 134542.52 kWh\n",
      "‚ö†Ô∏è  L∆∞·ª£ng ƒëi·ªán hi·ªán t·∫°i V∆Ø·ª¢T QU√Å ng∆∞·ª°ng! C·∫ßn ƒëi·ªÅu ch·ªânh features.\n",
      "   C·∫ßn gi·∫£m: 134469.16 kWh (99.9%)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ƒêang t·∫°o counterfactual explanations...\n",
      "(Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Permitted ranges cho continuous features:\n",
      "  sqm                      : [      0.00,   53899.58]\n",
      "  occupants                : [      0.00,    1534.50]\n",
      "  yearbuilt                : [      0.00,    2217.60]\n",
      "  numberoffloors           : [      0.00,      20.90]\n",
      "  airTemperature           : [      0.00,      56.02]\n",
      "  hour                     : [      0.00,      25.30]\n",
      "  day_of_week              : [      0.00,       6.60]\n",
      "  month                    : [      0.00,      13.10]\n",
      "  cloudCoverage            : [      0.00,       9.90]\n",
      "  windSpeed                : [      0.00,      26.62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ ƒê√£ t·∫°o xong counterfactual explanations!\n",
      "\n",
      "================================================================================\n",
      "COUNTERFACTUAL EXPLANATIONS - C√°c ph∆∞∆°ng √°n ƒëi·ªÅu ch·ªânh features\n",
      "================================================================================\n",
      "\n",
      "üìä Instance g·ªëc (hi·ªán t·∫°i):\n",
      "  L∆∞·ª£ng ƒëi·ªán d·ª± ƒëo√°n: 134542.52 kWh\n",
      "  Features (adjustable):\n",
      "    sqm: 39822.6\n",
      "    occupants: 0.0\n",
      "    yearbuilt: 0.0\n",
      "    numberoffloors: 0.0\n",
      "    airTemperature: 30.6\n",
      "    hour: 15\n",
      "    day_of_week: 2\n",
      "    month: 9\n",
      "    cloudCoverage: 0.0\n",
      "    windSpeed: 3.6\n",
      "    primaryspaceusage: Education\n",
      "    site_id: Bull\n",
      "    timezone: US/Central\n",
      "    season: Fall\n",
      "    is_weekend: 0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "C√°c ph∆∞∆°ng √°n ƒë·ªÅ xu·∫•t (Counterfactuals):\n",
      "--------------------------------------------------------------------------------\n",
      "Query instance (original outcome : 134543.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqm</th>\n",
       "      <th>occupants</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>numberoffloors</th>\n",
       "      <th>airTemperature</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>cloudCoverage</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>primaryspaceusage</th>\n",
       "      <th>site_id</th>\n",
       "      <th>timezone</th>\n",
       "      <th>season</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>electricity_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39822.601562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>Education</td>\n",
       "      <td>Bull</td>\n",
       "      <td>US/Central</td>\n",
       "      <td>Fall</td>\n",
       "      <td>0</td>\n",
       "      <td>134543.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sqm  occupants  yearbuilt  numberoffloors  airTemperature  hour  \\\n",
       "0  39822.601562        0.0        0.0             0.0            30.6    15   \n",
       "\n",
       "   day_of_week  month  cloudCoverage  windSpeed primaryspaceusage site_id  \\\n",
       "0            2      9            0.0        3.6         Education    Bull   \n",
       "\n",
       "     timezone season is_weekend  electricity_consumption  \n",
       "0  US/Central   Fall          0                 134543.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: [0, np.float64(73.36)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sqm</th>\n",
       "      <th>occupants</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>numberoffloors</th>\n",
       "      <th>airTemperature</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>cloudCoverage</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>primaryspaceusage</th>\n",
       "      <th>site_id</th>\n",
       "      <th>timezone</th>\n",
       "      <th>season</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>electricity_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>36.5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>21.2</td>\n",
       "      <td>Parking</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>356.8</td>\n",
       "      <td>-</td>\n",
       "      <td>46.3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Spring</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>552.5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Entertainment/public assembly</td>\n",
       "      <td>-</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>356.8</td>\n",
       "      <td>-</td>\n",
       "      <td>46.3</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Office</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sqm occupants yearbuilt numberoffloors airTemperature hour day_of_week  \\\n",
       "0   -      36.5         -              -           34.5    -           -   \n",
       "1   -         -     356.8              -           46.3    -           -   \n",
       "2   -     552.5         -              -            3.0    -           -   \n",
       "3   -         -     356.8              -           46.3    -           -   \n",
       "4   -         -         -              -           20.9   21           -   \n",
       "\n",
       "  month cloudCoverage windSpeed              primaryspaceusage  site_id  \\\n",
       "0     -             -      21.2                        Parking        -   \n",
       "1     -             -         -                              -        -   \n",
       "2     0             -         -  Entertainment/public assembly        -   \n",
       "3     -             -         -                              -        -   \n",
       "4     -             -         -                         Office  Peacock   \n",
       "\n",
       "        timezone  season is_weekend electricity_consumption  \n",
       "0              -       -          -                       -  \n",
       "1              -  Spring          -                       -  \n",
       "2  Europe/London       -          -                       -  \n",
       "3              -       -          -                       -  \n",
       "4              -       -          -                       -  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "================================================================================\n",
      "PH√ÇN T√çCH CHI TI·∫æT C√ÅC PH∆Ø∆†NG √ÅN\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è  L·ªói khi t·∫°o counterfactuals: 'NoneType' object is not iterable\n",
      "   C√≥ th·ªÉ do XGBoost model kh√¥ng t∆∞∆°ng th√≠ch ho√†n to√†n v·ªõi DiCE.\n",
      "   H√£y th·ª≠ s·ª≠ d·ª•ng method='genetic' ho·∫∑c ki·ªÉm tra l·∫°i model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/9j/40pxvw_12zl9rw6mldc3vvwr0000gn/T/ipykernel_91245/3958352869.py\", line 286, in <module>\n",
      "    for i, cf in enumerate(cf_examples, 1):\n",
      "                 ~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PH·∫¶N 4: S·ª¨ D·ª§NG DiCE ƒê·ªÇ G·ª¢I √ù ƒêI·ªÄU CH·ªàNH FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PH·∫¶N 4: S·ª¨ D·ª§NG DiCE ƒê·ªÇ G·ª¢I √ù ƒêI·ªÄU CH·ªàNH FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Chu·∫©n b·ªã d·ªØ li·ªáu cho DiCE\n",
    "# Ch·ªâ l·∫•y c√°c features c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c\n",
    "adjustable_features = [\n",
    "    'sqm', 'occupants', 'yearbuilt', 'numberoffloors',\n",
    "    'airTemperature', 'hour', 'day_of_week', 'month',\n",
    "    'cloudCoverage', 'windSpeed'\n",
    "]\n",
    "\n",
    "adjustable_categorical = [\n",
    "    'primaryspaceusage', 'site_id', 'timezone', 'season', 'is_weekend'\n",
    "]\n",
    "\n",
    "# L·∫•y c√°c features c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh (ph·∫£i c√≥ trong df_train)\n",
    "dice_features = [f for f in adjustable_features + adjustable_categorical if f in df_train.columns]\n",
    "\n",
    "print(f\"\\n‚úÖ Features cho DiCE: {dice_features}\")\n",
    "print(f\"   T·ªïng c·ªông: {len(dice_features)} features\")\n",
    "\n",
    "# Train m·ªôt model ri√™ng cho DiCE ch·ªâ v·ªõi adjustable features\n",
    "# (v√¨ lag features v√† rolling features kh√¥ng th·ªÉ ƒëi·ªÅu ch·ªânh ƒë∆∞·ª£c)\n",
    "print(\"\\nƒêang train model ri√™ng cho DiCE (ch·ªâ v·ªõi adjustable features)...\")\n",
    "\n",
    "# T·∫°o dataset ch·ªâ v·ªõi adjustable features\n",
    "X_dice = df_train[dice_features].copy()\n",
    "y_dice = df_train['electricity_consumption'].copy()\n",
    "\n",
    "# Th√™m building_id t·∫°m th·ªùi ƒë·ªÉ c√≥ th·ªÉ groupby (n·∫øu c√≥ trong df_train)\n",
    "if 'building_id' in df_train.columns:\n",
    "    X_dice['building_id'] = df_train['building_id'].values\n",
    "\n",
    "# Fill missing values\n",
    "for col in dice_features:\n",
    "    if col in X_dice.columns:\n",
    "        if col in adjustable_features:\n",
    "            # N·∫øu c√≥ building_id, groupby theo building_id, n·∫øu kh√¥ng th√¨ fillna tr·ª±c ti·∫øp\n",
    "            if 'building_id' in X_dice.columns:\n",
    "                X_dice[col] = X_dice.groupby('building_id')[col].transform(\n",
    "                    lambda x: x.fillna(x.median() if not x.isna().all() else 0)\n",
    "                )\n",
    "            else:\n",
    "                X_dice[col] = X_dice[col].fillna(X_dice[col].median() if not X_dice[col].isna().all() else 0)\n",
    "        else:\n",
    "            X_dice[col] = X_dice[col].fillna(\n",
    "                X_dice[col].mode()[0] if len(X_dice[col].mode()) > 0 else 'Unknown'\n",
    "            )\n",
    "\n",
    "# X√≥a building_id kh·ªèi X_dice tr∆∞·ªõc khi train (n·∫øu ƒë√£ th√™m)\n",
    "if 'building_id' in X_dice.columns and 'building_id' not in dice_features:\n",
    "    X_dice = X_dice.drop(columns=['building_id'])\n",
    "\n",
    "# L∆∞u b·∫£n g·ªëc v·ªõi categorical features d∆∞·ªõi d·∫°ng string (cho DiCE)\n",
    "X_dice_original = X_dice.copy()\n",
    "for col in adjustable_categorical:\n",
    "    if col in X_dice_original.columns:\n",
    "        X_dice_original[col] = X_dice_original[col].astype(str)\n",
    "\n",
    "# Encode categorical features cho training\n",
    "label_encoders_dice = {}\n",
    "for col in adjustable_categorical:\n",
    "    if col in X_dice.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_dice[col] = le.fit_transform(X_dice[col].astype(str))\n",
    "        label_encoders_dice[col] = le\n",
    "\n",
    "# Chia train/test theo th·ªùi gian\n",
    "df_train_sorted_dice = df_train.sort_values('timestamp')\n",
    "split_idx_dice = int(len(df_train_sorted_dice) * 0.8)\n",
    "\n",
    "X_train_dice = X_dice.iloc[:split_idx_dice]\n",
    "y_train_dice = y_dice.iloc[:split_idx_dice]\n",
    "X_test_dice = X_dice.iloc[split_idx_dice:]\n",
    "y_test_dice = y_dice.iloc[split_idx_dice:]\n",
    "\n",
    "# Train XGBoost model cho DiCE\n",
    "xgb_model_dice = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    ")\n",
    "\n",
    "xgb_model_dice.fit(\n",
    "    X_train_dice, y_train_dice,\n",
    "    eval_set=[(X_train_dice, y_train_dice), (X_test_dice, y_test_dice)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# ƒê√°nh gi√° model DiCE\n",
    "y_pred_dice = xgb_model_dice.predict(X_test_dice)\n",
    "dice_rmse = np.sqrt(mean_squared_error(y_test_dice, y_pred_dice))\n",
    "dice_r2 = r2_score(y_test_dice, y_pred_dice)\n",
    "\n",
    "print(f\"\\n‚úÖ Model DiCE Performance:\")\n",
    "print(f\"  RMSE: {dice_rmse:.2f} kWh\")\n",
    "print(f\"  R¬≤:   {dice_r2:.4f}\")\n",
    "\n",
    "# T·∫°o wrapper class cho model ƒë·ªÉ t·ª± ƒë·ªông encode categorical features\n",
    "class XGBoostWrapper:\n",
    "    \"\"\"Wrapper class ƒë·ªÉ t·ª± ƒë·ªông encode categorical features tr∆∞·ªõc khi predict\"\"\"\n",
    "    def __init__(self, model, label_encoders, categorical_features):\n",
    "        self.model = model\n",
    "        self.label_encoders = label_encoders\n",
    "        self.categorical_features = categorical_features\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict v·ªõi t·ª± ƒë·ªông encode categorical features\"\"\"\n",
    "        X_encoded = X.copy()\n",
    "        \n",
    "        # Encode categorical features\n",
    "        for col in self.categorical_features:\n",
    "            if col in X_encoded.columns:\n",
    "                if col in self.label_encoders:\n",
    "                    le = self.label_encoders[col]\n",
    "                    # Chuy·ªÉn ƒë·ªïi v·ªÅ string v√† encode\n",
    "                    X_encoded[col] = X_encoded[col].astype(str)\n",
    "                    # X·ª≠ l√Ω c√°c gi√° tr·ªã ch∆∞a th·∫•y (unknown values)\n",
    "                    X_encoded[col] = X_encoded[col].apply(\n",
    "                        lambda x: x if x in le.classes_ else le.classes_[0]\n",
    "                    )\n",
    "                    X_encoded[col] = le.transform(X_encoded[col])\n",
    "                else:\n",
    "                    # N·∫øu kh√¥ng c√≥ encoder, gi·ªØ nguy√™n (c√≥ th·ªÉ l√† integer r·ªìi)\n",
    "                    if X_encoded[col].dtype == 'object':\n",
    "                        # N·∫øu l√† object nh∆∞ng kh√¥ng c√≥ encoder, chuy·ªÉn v·ªÅ 0\n",
    "                        X_encoded[col] = 0\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o t·∫•t c·∫£ columns l√† numeric\n",
    "        for col in X_encoded.columns:\n",
    "            if X_encoded[col].dtype == 'object':\n",
    "                X_encoded[col] = pd.to_numeric(X_encoded[col], errors='coerce').fillna(0)\n",
    "        \n",
    "        return self.model.predict(X_encoded)\n",
    "\n",
    "# T·∫°o wrapped model\n",
    "xgb_model_wrapped = XGBoostWrapper(\n",
    "    xgb_model_dice,\n",
    "    label_encoders_dice,\n",
    "    adjustable_categorical\n",
    ")\n",
    "\n",
    "# T·∫°o dataframe cho DiCE (s·ª≠ d·ª•ng b·∫£n g·ªëc v·ªõi categorical features d∆∞·ªõi d·∫°ng string)\n",
    "X_train_dice_original = X_dice_original.iloc[:split_idx_dice]\n",
    "df_for_dice = pd.concat([X_train_dice_original, y_train_dice], axis=1)\n",
    "df_for_dice = df_for_dice.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset cho DiCE: {df_for_dice.shape}\")\n",
    "print(f\"   Features: {list(df_for_dice.columns[:-1])}\")\n",
    "print(f\"   Target: electricity_consumption\")\n",
    "\n",
    "# T·∫°o DiCE Data object\n",
    "dice_data = dice_ml.Data(\n",
    "    dataframe=df_for_dice,\n",
    "    continuous_features=[f for f in adjustable_features if f in df_for_dice.columns],\n",
    "    outcome_name='electricity_consumption'\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ DiCE Data object ƒë√£ ƒë∆∞·ª£c t·∫°o!\")\n",
    "\n",
    "# T·∫°o DiCE Model object (s·ª≠ d·ª•ng wrapped model)\n",
    "dice_model = dice_ml.Model(\n",
    "    model=xgb_model_wrapped,  # S·ª≠ d·ª•ng wrapped model ƒë·ªÉ t·ª± ƒë·ªông encode\n",
    "    backend='sklearn',\n",
    "    model_type='regressor'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ DiCE Model object ƒë√£ ƒë∆∞·ª£c t·∫°o!\")\n",
    "\n",
    "# T·∫°o DiCE Explainer\n",
    "explainer = Dice(dice_data, dice_model, method='random')  # C√≥ th·ªÉ ƒë·ªïi th√†nh 'genetic' n·∫øu mu·ªën k·∫øt qu·∫£ t·ªët h∆°n\n",
    "\n",
    "print(\"‚úÖ DiCE Explainer ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi method='random'!\")\n",
    "print(\"   (C√≥ th·ªÉ ƒë·ªïi th√†nh 'genetic' n·∫øu mu·ªën k·∫øt qu·∫£ t·ªët h∆°n nh∆∞ng ch·∫≠m h∆°n)\")\n",
    "\n",
    "# Ch·ªçn m·ªôt building ƒë·ªÉ t·∫°o counterfactual explanations\n",
    "# L·∫•y m·ªôt building c√≥ l∆∞·ª£ng ƒëi·ªán ti√™u th·ª• cao t·ª´ training data\n",
    "high_consumption_idx_dice = y_train_dice.idxmax()\n",
    "\n",
    "# T·∫°o query_instance cho DiCE (s·ª≠ d·ª•ng b·∫£n g·ªëc ch∆∞a encode, v·ªõi categorical d∆∞·ªõi d·∫°ng string)\n",
    "query_instance_dice = X_train_dice_original.loc[[high_consumption_idx_dice]][dice_features].copy()\n",
    "\n",
    "# L·∫•y th√¥ng tin building t·ª´ df_train\n",
    "building_info = df_train_sorted_dice.loc[high_consumption_idx_dice]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Building ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ t·ªëi ∆∞u:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"  Building ID: {building_info.get('building_id', 'N/A')}\")\n",
    "print(f\"  L∆∞·ª£ng ƒëi·ªán ti√™u th·ª• th·ª±c t·∫ø: {y_train_dice.loc[high_consumption_idx_dice]:.2f} kWh\")\n",
    "print(f\"\\nFeatures hi·ªán t·∫°i (adjustable features):\")\n",
    "for feature in dice_features:\n",
    "    if feature in query_instance_dice.columns:\n",
    "        val = query_instance_dice[feature].iloc[0]\n",
    "        print(f\"  {feature:25s}: {val}\")\n",
    "\n",
    "# D·ª± ƒëo√°n l∆∞·ª£ng ƒëi·ªán v·ªõi model DiCE (ch·ªâ v·ªõi adjustable features)\n",
    "current_prediction = xgb_model_wrapped.predict(query_instance_dice[dice_features])[0]\n",
    "print(f\"\\n  D·ª± ƒëo√°n t·ª´ model DiCE: {current_prediction:.2f} kWh\")\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a threshold\n",
    "THRESHOLD = np.percentile(y_dice, 50)  # 50th percentile (median) c·ªßa y_dice\n",
    "# Ho·∫∑c c√≥ th·ªÉ ƒë·∫∑t th·ªß c√¥ng: THRESHOLD = 500\n",
    "\n",
    "print(f\"\\nüìä Ng∆∞·ª°ng t·ªëi ƒëa cho ph√©p: {THRESHOLD:.2f} kWh\")\n",
    "print(f\"üìä L∆∞·ª£ng ƒëi·ªán hi·ªán t·∫°i: {current_prediction:.2f} kWh\")\n",
    "\n",
    "if current_prediction > THRESHOLD:\n",
    "    print(f\"‚ö†Ô∏è  L∆∞·ª£ng ƒëi·ªán hi·ªán t·∫°i V∆Ø·ª¢T QU√Å ng∆∞·ª°ng! C·∫ßn ƒëi·ªÅu ch·ªânh features.\")\n",
    "    reduction_needed = current_prediction - THRESHOLD\n",
    "    reduction_pct = (reduction_needed / current_prediction) * 100\n",
    "    print(f\"   C·∫ßn gi·∫£m: {reduction_needed:.2f} kWh ({reduction_pct:.1f}%)\")\n",
    "else:\n",
    "    print(f\"‚úÖ L∆∞·ª£ng ƒëi·ªán hi·ªán t·∫°i trong ng∆∞·ª°ng cho ph√©p.\")\n",
    "\n",
    "# T·∫°o counterfactual explanations\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"ƒêang t·∫°o counterfactual explanations...\")\n",
    "print(\"(Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# X√°c ƒë·ªãnh permitted_range d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø\n",
    "permitted_range = {}\n",
    "for col in adjustable_features:\n",
    "    if col in df_for_dice.columns:\n",
    "        col_min = df_for_dice[col].min()\n",
    "        col_max = df_for_dice[col].max()\n",
    "        # M·ªü r·ªông m·ªôt ch√∫t ƒë·ªÉ c√≥ nhi·ªÅu l·ª±a ch·ªçn h∆°n\n",
    "        col_range = col_max - col_min\n",
    "        permitted_range[col] = [max(0, col_min - 0.1 * col_range), col_max + 0.1 * col_range]\n",
    "\n",
    "print(f\"\\nPermitted ranges cho continuous features:\")\n",
    "for col, (min_val, max_val) in permitted_range.items():\n",
    "    print(f\"  {col:25s}: [{min_val:10.2f}, {max_val:10.2f}]\")\n",
    "\n",
    "# T·∫°o counterfactuals\n",
    "# S·ª≠ d·ª•ng query_instance_dice (ch·ªâ c√≥ adjustable features) cho DiCE\n",
    "try:\n",
    "    counterfactuals = explainer.generate_counterfactuals(\n",
    "        query_instance_dice,  # S·ª≠ d·ª•ng query_instance_dice thay v√¨ query_instance\n",
    "        total_CFs=5,  # S·ªë l∆∞·ª£ng counterfactual examples\n",
    "        desired_range=[0, THRESHOLD],  # Kho·∫£ng gi√° tr·ªã mong mu·ªën\n",
    "        permitted_range=permitted_range,  # Gi·ªõi h·∫°n ph·∫°m vi thay ƒë·ªïi\n",
    "    )\n",
    "    print(\"\\n‚úÖ ƒê√£ t·∫°o xong counterfactual explanations!\")\n",
    "    \n",
    "    # Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"COUNTERFACTUAL EXPLANATIONS - C√°c ph∆∞∆°ng √°n ƒëi·ªÅu ch·ªânh features\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nüìä Instance g·ªëc (hi·ªán t·∫°i):\")\n",
    "    print(f\"  L∆∞·ª£ng ƒëi·ªán d·ª± ƒëo√°n: {current_prediction:.2f} kWh\")\n",
    "    print(f\"  Features (adjustable):\")\n",
    "    for feature in dice_features:\n",
    "        if feature in query_instance_dice.columns:\n",
    "            print(f\"    {feature}: {query_instance_dice[feature].iloc[0]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"C√°c ph∆∞∆°ng √°n ƒë·ªÅ xu·∫•t (Counterfactuals):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Hi·ªÉn th·ªã counterfactuals\n",
    "    cf_df = counterfactuals.visualize_as_dataframe(show_only_changes=True)\n",
    "    print(cf_df)\n",
    "    \n",
    "    # Ph√¢n t√≠ch chi ti·∫øt c√°c ph∆∞∆°ng √°n\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PH√ÇN T√çCH CHI TI·∫æT C√ÅC PH∆Ø∆†NG √ÅN\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # L·∫•y counterfactual examples\n",
    "    cf_examples = counterfactuals.cf_examples_list[0].final_cfs_list\n",
    "    \n",
    "    for i, cf in enumerate(cf_examples, 1):\n",
    "        # Chuy·ªÉn ƒë·ªïi v·ªÅ DataFrame\n",
    "        cf_df_single = pd.DataFrame([cf], columns=dice_features)\n",
    "        \n",
    "        # D·ª± ƒëo√°n l∆∞·ª£ng ƒëi·ªán cho counterfactual n√†y (s·ª≠ d·ª•ng wrapped model)\n",
    "        cf_prediction = xgb_model_wrapped.predict(cf_df_single[dice_features])[0]\n",
    "        \n",
    "        print(f\"\\n--- Ph∆∞∆°ng √°n {i} ---\")\n",
    "        print(f\"üìä D·ª± ƒëo√°n l∆∞·ª£ng ƒëi·ªán: {cf_prediction:.2f} kWh (m·ª•c ti√™u: <= {THRESHOLD:.2f} kWh)\")\n",
    "        \n",
    "        if cf_prediction <= THRESHOLD:\n",
    "            print(\"  ‚úÖ ƒê·∫°t m·ª•c ti√™u!\")\n",
    "        else:\n",
    "            print(\"  ‚ö†Ô∏è  Ch∆∞a ƒë·∫°t m·ª•c ti√™u\")\n",
    "        \n",
    "        # So s√°nh v·ªõi instance g·ªëc\n",
    "        print(\"\\n  Thay ƒë·ªïi so v·ªõi hi·ªán t·∫°i:\")\n",
    "        for col in dice_features:\n",
    "            if col in query_instance_dice.columns and col in cf_df_single.columns:\n",
    "                original_val = query_instance_dice[col].iloc[0]\n",
    "                new_val = cf_df_single[col].iloc[0]\n",
    "                \n",
    "                if pd.isna(original_val) or pd.isna(new_val):\n",
    "                    continue\n",
    "                \n",
    "                # X·ª≠ l√Ω cho c·∫£ s·ªë v√† categorical\n",
    "                if isinstance(original_val, (int, float)) and isinstance(new_val, (int, float)):\n",
    "                    if abs(original_val - new_val) > 0.01:  # C√≥ thay ƒë·ªïi ƒë√°ng k·ªÉ\n",
    "                        change = new_val - original_val\n",
    "                        change_pct = (change / original_val * 100) if original_val != 0 else 0\n",
    "                        print(f\"    {col:25s}: {original_val:10.2f} ‚Üí {new_val:10.2f} (thay ƒë·ªïi: {change:+.2f}, {change_pct:+.1f}%)\")\n",
    "                else:\n",
    "                    if original_val != new_val:\n",
    "                        print(f\"    {col:25s}: {original_val} ‚Üí {new_val}\")\n",
    "        \n",
    "        reduction = current_prediction - cf_prediction\n",
    "        reduction_pct = (reduction / current_prediction * 100) if current_prediction > 0 else 0\n",
    "        print(f\"\\n  ‚úÖ Gi·∫£m l∆∞·ª£ng ƒëi·ªán: {reduction:.2f} kWh ({reduction_pct:.1f}%)\")\n",
    "    \n",
    "    # L∆∞u counterfactuals\n",
    "    cf_df.to_csv('/root/projects/cmcproject/grid_balancer/reverse_LLM/counterfactuals_results.csv', index=False)\n",
    "    print(f\"\\n‚úÖ ƒê√£ l∆∞u counterfactuals v√†o: counterfactuals_results.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  L·ªói khi t·∫°o counterfactuals: {e}\")\n",
    "    print(\"   C√≥ th·ªÉ do XGBoost model kh√¥ng t∆∞∆°ng th√≠ch ho√†n to√†n v·ªõi DiCE.\")\n",
    "    print(\"   H√£y th·ª≠ s·ª≠ d·ª•ng method='genetic' ho·∫∑c ki·ªÉm tra l·∫°i model.\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e29f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
