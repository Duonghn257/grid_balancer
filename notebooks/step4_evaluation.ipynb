{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93708228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('..')\n",
    "import joblib\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e322c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature columns\n",
    "model_dir = \"./models_1578_csv\"\n",
    "# feature columns\n",
    "X_cols = [\n",
    "    \"hour\",\"dayofweek\",\"is_weekend\",\"month\",\n",
    "    # \"lag_24\",\"rolling_24\",\n",
    "    # \"electricity_current\",\n",
    "    \"airTemperature\", \"dewTemperature\", \"windSpeed\",\n",
    "    # \"temp_lag_1h\",\"dewTemperature_lag_1h\", \"windSpeed_lag_1h\",\n",
    "    # \"sqft\", \n",
    "    \"sqm\", \"primaryspaceusage\", \"site_id\", \"building_id\",\n",
    "    \"Chilledwater\", \"Hotwater\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7688833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# MultiColumnLabelEncoder\n",
    "# =============================\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self, categorical_cols, unknown_token=\"unknown\"):\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.unknown_token = unknown_token\n",
    "        self.encoders = {}\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        for col in self.categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            values = df[col].fillna(self.unknown_token).astype(str)\n",
    "            classes = values.unique().tolist()\n",
    "            if self.unknown_token not in classes:\n",
    "                classes.append(self.unknown_token)\n",
    "            le.fit(classes)\n",
    "            self.encoders[col] = le\n",
    "        return self\n",
    "\n",
    "    def transform(self, df: pd.DataFrame):\n",
    "        df = df.copy()\n",
    "        for col, le in self.encoders.items():\n",
    "            values = df[col].fillna(self.unknown_token).astype(str)\n",
    "            # Những giá trị không nằm trong classes_ được map sang unknown_token\n",
    "            values = values.where(values.isin(le.classes_), self.unknown_token)\n",
    "            df[col] = le.transform(values)\n",
    "        return df\n",
    "\n",
    "    def inverse_transform(self, df: pd.DataFrame):\n",
    "        \"\"\"Decode số đã encode về giá trị gốc\"\"\"\n",
    "        df = df.copy()\n",
    "        for col, le in self.encoders.items():\n",
    "            if col in df.columns:\n",
    "                df[col] = le.inverse_transform(df[col].astype(int))\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df: pd.DataFrame):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)\n",
    "\n",
    "    def save(self, path: str):\n",
    "        joblib.dump({\n",
    "            \"categorical_cols\": self.categorical_cols,\n",
    "            \"unknown_token\": self.unknown_token,\n",
    "            \"encoders\": self.encoders\n",
    "        }, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path: str):\n",
    "        data = joblib.load(path)\n",
    "        obj = cls(\n",
    "            categorical_cols=data[\"categorical_cols\"],\n",
    "            unknown_token=data[\"unknown_token\"]\n",
    "        )\n",
    "        obj.encoders = data[\"encoders\"]\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b1e7d",
   "metadata": {},
   "source": [
    "# Forecast & đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af91447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model_hour_1.pkl\n",
      "Loaded model_hour_2.pkl\n",
      "Loaded model_hour_3.pkl\n",
      "Loaded model_hour_4.pkl\n",
      "Loaded model_hour_5.pkl\n",
      "Loaded model_hour_6.pkl\n",
      "Loaded model_hour_7.pkl\n",
      "Loaded model_hour_8.pkl\n",
      "Loaded model_hour_9.pkl\n",
      "Loaded model_hour_10.pkl\n",
      "Loaded model_hour_11.pkl\n",
      "Loaded model_hour_12.pkl\n",
      "Loaded model_hour_13.pkl\n",
      "Loaded model_hour_14.pkl\n",
      "Loaded model_hour_15.pkl\n",
      "Loaded model_hour_16.pkl\n",
      "Loaded model_hour_17.pkl\n",
      "Loaded model_hour_18.pkl\n",
      "Loaded model_hour_19.pkl\n",
      "Loaded model_hour_20.pkl\n",
      "Loaded model_hour_21.pkl\n",
      "Loaded model_hour_22.pkl\n",
      "Loaded model_hour_23.pkl\n",
      "Loaded model_hour_24.pkl\n"
     ]
    }
   ],
   "source": [
    "forecast_horizon = 24\n",
    "models = []\n",
    "\n",
    "for h in range(forecast_horizon):\n",
    "    model_path = os.path.join(model_dir, f\"model_hour_{h+1}.pkl\")\n",
    "    if os.path.exists(model_path):\n",
    "        model = joblib.load(model_path)\n",
    "        models.append(model)\n",
    "        print(f\"Loaded model_hour_{h+1}.pkl\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"{model_path} not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f935c893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data_df = pd.read_csv(path)\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b020b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              feature  importance\n",
      "7                 sqm   99.056515\n",
      "10        building_id   42.339606\n",
      "11       Chilledwater   33.508483\n",
      "8   primaryspaceusage   29.181334\n",
      "12           Hotwater   17.540473\n",
      "0                hour    8.116297\n",
      "9             site_id    5.088810\n",
      "1           dayofweek    1.735711\n",
      "5      dewTemperature    0.905242\n",
      "4      airTemperature    0.698417\n",
      "3               month    0.335651\n",
      "2          is_weekend    0.182269\n",
      "6           windSpeed    0.091959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# lấy 1 model (ví dụ horizon = 1)\n",
    "model = models[0]\n",
    "data_encoded = \"data_1578_csv/test_encode.csv\"\n",
    "data_frame = load_data(data_encoded)\n",
    "# lấy 1 tập test nhỏ để test nhanh\n",
    "# df_test = data_frame.sample(20000, random_state=42)\n",
    "df_test = data_frame.copy()\n",
    "X_test = df_test[X_cols]\n",
    "y_test = df_test[\"Electricity\"]\n",
    "\n",
    "r = permutation_importance(\n",
    "    model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=5,\n",
    "    random_state=42,\n",
    "    scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    \"feature\": X_cols,\n",
    "    \"importance\": r.importances_mean\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786e3587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250965\n"
     ]
    }
   ],
   "source": [
    "data_encoded = \"data_1578_csv/test_encode.csv\"\n",
    "data_frame = load_data(data_encoded)\n",
    "data_frame[\"timestamp\"] = pd.to_datetime(data_frame[\"timestamp\"])\n",
    "print(len(data_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef56a326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73, 22, 86, 79, 13, 24,  0, 21,  3, 30,  6, 12, 54, 63, 16, 85, 49,\n",
       "       56, 11, 50, 10, 23, 62, 60, 43, 17, 34, 84, 25,  4, 38, 47, 74, 72,\n",
       "       65, 78, 76, 82, 14, 53, 68, 45, 61, 31, 59, 41, 58, 26, 39, 33, 83,\n",
       "        9, 80, 27, 36, 44, 77,  5, 46, 67,  2, 64, 37,  1, 66, 75, 19, 81,\n",
       "       20, 15, 40, 55, 70, 69, 48, 71, 18, 35, 28, 42,  8, 52, 51, 29, 57,\n",
       "        7, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame[\"building_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8072ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Appended 250965 rows.\n"
     ]
    }
   ],
   "source": [
    "# CACH 2\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "results_file = \"models_1578_csv/df_result_test.csv\"\n",
    "metric_file = \"models_1578_csv/metrics_by_building_with_avg.csv\"\n",
    "forecast_horizon = 1\n",
    "\n",
    "# =============================\n",
    "# 1. Load kết quả cũ (nếu có)\n",
    "# =============================\n",
    "if os.path.exists(results_file):\n",
    "    df_existing = pd.read_csv(results_file, parse_dates=[\"timestamp\", \"t0\"])\n",
    "    existing_keys = set(\n",
    "        zip(df_existing[\"t0\"], df_existing[\"building_id\"], df_existing[\"horizon\"])\n",
    "    )\n",
    "else:\n",
    "    existing_keys = set()\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# =============================\n",
    "# 2. Predict theo từng building\n",
    "# =============================\n",
    "for building_id, df_b in data_frame.groupby(\"building_id\"):\n",
    "    df_b = df_b.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    # giữ bản sao để cập nhật Electricity bằng pred\n",
    "    df_work = df_b.copy()\n",
    "\n",
    "    # =============================\n",
    "    # Loop theo horizon (recursive)\n",
    "    # =============================\n",
    "    for h in range(1, forecast_horizon + 1):\n",
    "        model = models[h - 1]\n",
    "\n",
    "        # Feature tại t\n",
    "        X = df_work[X_cols]\n",
    "\n",
    "        # Predict batch\n",
    "        preds = model.predict(X)\n",
    "\n",
    "        # Thời điểm dự đoán\n",
    "        t0 = df_work[\"timestamp\"]\n",
    "        ts = t0 + timedelta(hours=h)\n",
    "\n",
    "        # Actual (nếu có)\n",
    "        df_actual = df_b[[\"timestamp\", \"Electricity\"]] \\\n",
    "            .rename(columns={\n",
    "                \"timestamp\": \"ts\",\n",
    "                \"Electricity\": \"actual\"\n",
    "            })\n",
    "\n",
    "        df_h = pd.DataFrame({\n",
    "            \"building_id\": building_id,\n",
    "            \"t0\": t0,\n",
    "            \"horizon\": h,\n",
    "            \"timestamp\": ts,\n",
    "            \"pred\": preds\n",
    "        })\n",
    "\n",
    "        df_h = df_h.merge(\n",
    "            df_actual,\n",
    "            left_on=\"timestamp\",\n",
    "            right_on=\"ts\",\n",
    "            how=\"left\"\n",
    "        ).drop(columns=\"ts\")\n",
    "\n",
    "        # =============================\n",
    "        # Bỏ các dòng đã có\n",
    "        # =============================\n",
    "        mask_new = ~df_h.apply(\n",
    "            lambda r: (r.t0, r.building_id, r.horizon) in existing_keys,\n",
    "            axis=1\n",
    "        )\n",
    "        df_h = df_h.loc[mask_new]\n",
    "\n",
    "        all_results.append(df_h)\n",
    "\n",
    "        # =============================\n",
    "        # UPDATE Electricity để recursive\n",
    "        # =============================\n",
    "        df_work[\"Electricity\"] = preds\n",
    "\n",
    "        # cập nhật lag & rolling cho bước sau\n",
    "        df_work[\"lag_24\"] = df_work[\"Electricity\"].shift(24)\n",
    "        df_work[\"rolling_24\"] = df_work[\"Electricity\"].rolling(24).mean()\n",
    "\n",
    "# =============================\n",
    "# 3. Gộp & lưu\n",
    "# =============================\n",
    "df_result = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "df_result[[\n",
    "    \"building_id\",\n",
    "    \"t0\",\n",
    "    \"horizon\",\n",
    "    \"timestamp\",\n",
    "    \"actual\",\n",
    "    \"pred\"\n",
    "]].to_csv(\n",
    "    results_file,\n",
    "    mode=\"a\",\n",
    "    index=False,\n",
    "    header=not os.path.exists(results_file)\n",
    ")\n",
    "\n",
    "print(f\"Done. Appended {len(df_result)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a75167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>t0</th>\n",
       "      <th>horizon</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-31 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-31 01:00:00</td>\n",
       "      <td>49.997841</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-31 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-31 02:00:00</td>\n",
       "      <td>29.613825</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-31 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-31 03:00:00</td>\n",
       "      <td>24.540413</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-31 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-31 04:00:00</td>\n",
       "      <td>22.834240</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-31 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-31 05:00:00</td>\n",
       "      <td>23.257473</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250960</th>\n",
       "      <td>86</td>\n",
       "      <td>2017-12-31 19:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-31 20:00:00</td>\n",
       "      <td>304.633820</td>\n",
       "      <td>203.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250961</th>\n",
       "      <td>86</td>\n",
       "      <td>2017-12-31 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-31 21:00:00</td>\n",
       "      <td>306.207336</td>\n",
       "      <td>210.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250962</th>\n",
       "      <td>86</td>\n",
       "      <td>2017-12-31 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-31 22:00:00</td>\n",
       "      <td>346.717407</td>\n",
       "      <td>666.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250963</th>\n",
       "      <td>86</td>\n",
       "      <td>2017-12-31 22:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-12-31 23:00:00</td>\n",
       "      <td>440.768982</td>\n",
       "      <td>725.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250964</th>\n",
       "      <td>86</td>\n",
       "      <td>2017-12-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>444.884735</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250965 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id                  t0  horizon           timestamp  \\\n",
       "0                 0 2017-08-31 00:00:00        1 2017-08-31 01:00:00   \n",
       "1                 0 2017-08-31 01:00:00        1 2017-08-31 02:00:00   \n",
       "2                 0 2017-08-31 02:00:00        1 2017-08-31 03:00:00   \n",
       "3                 0 2017-08-31 03:00:00        1 2017-08-31 04:00:00   \n",
       "4                 0 2017-08-31 04:00:00        1 2017-08-31 05:00:00   \n",
       "...             ...                 ...      ...                 ...   \n",
       "250960           86 2017-12-31 19:00:00        1 2017-12-31 20:00:00   \n",
       "250961           86 2017-12-31 20:00:00        1 2017-12-31 21:00:00   \n",
       "250962           86 2017-12-31 21:00:00        1 2017-12-31 22:00:00   \n",
       "250963           86 2017-12-31 22:00:00        1 2017-12-31 23:00:00   \n",
       "250964           86 2017-12-31 23:00:00        1 2018-01-01 00:00:00   \n",
       "\n",
       "              pred  actual  \n",
       "0        49.997841   23.00  \n",
       "1        29.613825   23.00  \n",
       "2        24.540413   23.00  \n",
       "3        22.834240   23.00  \n",
       "4        23.257473   10.00  \n",
       "...            ...     ...  \n",
       "250960  304.633820  203.75  \n",
       "250961  306.207336  210.74  \n",
       "250962  346.717407  666.04  \n",
       "250963  440.768982  725.08  \n",
       "250964  444.884735     NaN  \n",
       "\n",
       "[250965 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "545fc552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248797\n",
      "   building_id       RMSE        MAE         R2   SMAPE(%)  \\\n",
      "0           66  22.039427  14.512384   0.771203   2.866225   \n",
      "1           60   3.913230   2.576268   0.219644   3.301658   \n",
      "2           58  42.710907  33.760358   0.336185   3.618728   \n",
      "3           44  34.701059  22.911365  -0.178857   3.634488   \n",
      "4           37  49.861755  37.071978  -0.156219   3.814460   \n",
      "..         ...        ...        ...        ...        ...   \n",
      "83          81  16.183952  12.476889   0.002378  69.379779   \n",
      "84          35  22.231588  21.551894 -12.851613  81.106690   \n",
      "85           0  47.570566  36.854622   0.196392  93.800854   \n",
      "86          38  50.802557  45.461243   0.465695  99.702020   \n",
      "87         TBC  24.481026  18.595717   0.005730  17.802577   \n",
      "\n",
      "             building_name  \n",
      "0    Fox_education_Yolande  \n",
      "1     Fox_education_Stacia  \n",
      "2     Fox_education_Otilia  \n",
      "3     Fox_education_Gloria  \n",
      "4     Fox_education_Claude  \n",
      "..                     ...  \n",
      "83        Fox_office_Essie  \n",
      "84     Fox_education_Ashli  \n",
      "85  Eagle_assembly_Candice  \n",
      "86     Fox_education_Delma  \n",
      "87                     NaN  \n",
      "\n",
      "[88 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# =============================\n",
    "# Load kết quả\n",
    "# =============================\n",
    "\n",
    "df_result = pd.read_csv(results_file).dropna()\n",
    "print(len(df_result))\n",
    "# =============================\n",
    "# Hàm tính SMAPE\n",
    "# =============================\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# =============================\n",
    "# Tính metric từng building\n",
    "# =============================\n",
    "metrics_by_building = []\n",
    "\n",
    "for building, df_b in df_result.groupby(\"building_id\"):\n",
    "    actual = df_b[\"actual\"].values\n",
    "    pred = df_b[\"pred\"].values\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    smape_val = smape(actual, pred)\n",
    "    \n",
    "    metrics_by_building.append({\n",
    "        \"building_id\": building,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2\": r2,\n",
    "        \"SMAPE(%)\": smape_val\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_by_building)\n",
    "encoder = MultiColumnLabelEncoder.load(f\"{model_dir}/categorical_encoder.pkl\")\n",
    "df_metrics[\"building_name\"] = encoder.encoders[\"building_id\"].inverse_transform(df_metrics[\"building_id\"].astype(int))\n",
    "df_metrics_sorted = df_metrics.sort_values(\"SMAPE(%)\", ascending=True).reset_index(drop=True)\n",
    "# =============================\n",
    "# Tính trung bình trên tất cả building\n",
    "# =============================\n",
    "average_metrics = df_metrics_sorted[[\"RMSE\", \"MAE\", \"R2\", \"SMAPE(%)\"]].mean()\n",
    "average_metrics[\"building_id\"] = \"TBC\"  # thêm dòng trung bình\n",
    "df_metrics_sorted = pd.concat([df_metrics_sorted, pd.DataFrame([average_metrics])], ignore_index=True)\n",
    "\n",
    "# =============================\n",
    "# Hiển thị và lưu bảng metrics\n",
    "# =============================\n",
    "print(df_metrics_sorted)\n",
    "df_metrics_sorted.to_csv(metric_file, index=False)\n",
    "\n",
    "\n",
    "order = df_metrics_sorted[df_metrics_sorted[\"building_id\"]!=\"TBC\"][\"building_id\"]\n",
    "df_result[\"building_id\"] = pd.Categorical(df_result[\"building_id\"], order, ordered=True)\n",
    "df_result = df_result.sort_values([\"building_id\", \"timestamp\"])\n",
    "df_result.to_csv(results_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541a1c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fox_education_Yolande',\n",
       " 'Fox_education_Stacia',\n",
       " 'Fox_education_Otilia',\n",
       " 'Fox_education_Gloria',\n",
       " 'Fox_education_Claude',\n",
       " 'Fox_office_Alice',\n",
       " 'Fox_assembly_Renna',\n",
       " 'Fox_education_Wendell',\n",
       " 'Eagle_office_Francis',\n",
       " 'Fox_education_Dominique',\n",
       " 'Eagle_education_Will',\n",
       " 'Fox_education_Eldon',\n",
       " 'Fox_education_Leona',\n",
       " 'Fox_public_Martin',\n",
       " 'Eagle_education_Luther',\n",
       " 'Fox_lodging_Wallace',\n",
       " 'Fox_office_Bernard',\n",
       " 'Fox_education_Marlana',\n",
       " 'Fox_education_Leota',\n",
       " 'Eagle_education_Samantha',\n",
       " 'Fox_education_Virgil',\n",
       " 'Fox_lodging_Frances',\n",
       " 'Eagle_education_Shanna',\n",
       " 'Fox_education_Andre',\n",
       " 'Fox_education_Geoffrey',\n",
       " 'Fox_education_Nilda',\n",
       " 'Eagle_public_Preston',\n",
       " 'Fox_education_Lilly',\n",
       " 'Eagle_office_Sonya',\n",
       " 'Fox_education_Jaclyn',\n",
       " 'Fox_office_Edythe',\n",
       " 'Fox_education_Long',\n",
       " 'Fox_lodging_Isabell',\n",
       " 'Fox_lodging_Stephen',\n",
       " 'Fox_lodging_Morris',\n",
       " 'Fox_education_Louie',\n",
       " 'Fox_assembly_Johnnie',\n",
       " 'Eagle_lodging_Stephanie',\n",
       " 'Eagle_office_Randolph',\n",
       " 'Fox_education_Ollie',\n",
       " 'Eagle_office_Yadira',\n",
       " 'Fox_education_Suzan',\n",
       " 'Fox_education_Melinda',\n",
       " 'Fox_lodging_Jina',\n",
       " 'Fox_education_Theodore',\n",
       " 'Fox_lodging_Helen',\n",
       " 'Eagle_office_Ryan',\n",
       " 'Fox_lodging_Warren',\n",
       " 'Eagle_office_Jeff',\n",
       " 'Fox_assembly_Emma',\n",
       " 'Fox_education_John',\n",
       " 'Eagle_assembly_Josie',\n",
       " 'Fox_education_Kim',\n",
       " 'Eagle_public_Minnie',\n",
       " 'Fox_assembly_Audrey',\n",
       " 'Eagle_office_Henriette',\n",
       " 'Eagle_office_Isidro',\n",
       " 'Fox_education_Dewayne',\n",
       " 'Eagle_office_Elvis',\n",
       " 'Eagle_office_Donovan']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_sorted[:60][\"building_name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb3ce8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
