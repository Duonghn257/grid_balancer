#!/usr/bin/env python3
"""
Script 6: Training XGBoost Model cho DiCE Integration
Train XGBoost model vá»›i wrapper class Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i DiCE
"""

import pandas as pd
import numpy as np
import warnings
from pathlib import Path
import os
import json
import pickle
from datetime import datetime

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error
import xgboost as xgb

warnings.filterwarnings('ignore')

print("=" * 80)
print("TRAINING XGBOOST MODEL CHO DiCE INTEGRATION")
print("=" * 80)

# ============================================================================
# 1. LOAD Dá»® LIá»†U ÄÃƒ Xá»¬ LÃ
# ============================================================================

print("\n" + "=" * 80)
print("BÆ¯á»šC 1: LOAD Dá»® LIá»†U")
print("=" * 80)

print("\nğŸ“‚ Äang load dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½...")
df = pd.read_parquet("./output/processed_data.parquet")

print(f"âœ… Dataset shape: {df.shape}")
print(f"   - Sá»‘ records: {len(df)}")
print(f"   - Sá»‘ buildings: {df['building_id'].nunique()}")

# Load features info
with open('output/features_info.json', 'r') as f:
    features_info = json.load(f)

# ============================================================================
# 2. CHUáº¨N Bá»Š Dá»® LIá»†U CHO TRAINING
# ============================================================================

print("\n" + "=" * 80)
print("BÆ¯á»šC 2: CHUáº¨N Bá»Š Dá»® LIá»†U")
print("=" * 80)

# Chá»n subset buildings Ä‘á»ƒ training (cÃ³ thá»ƒ Ä‘iá»u chá»‰nh)
print("\nğŸ“Š Chá»n subset buildings Ä‘á»ƒ training...")
np.random.seed(42)
sample_size = min(20000, df['building_id'].nunique())  # CÃ³ thá»ƒ tÄƒng lÃªn Ä‘á»ƒ train toÃ n bá»™
sample_buildings = np.random.choice(
    df['building_id'].unique(), 
    size=sample_size, 
    replace=False
)
df_train = df[df['building_id'].isin(sample_buildings)].copy()

print(f"âœ… ÄÃ£ chá»n {len(sample_buildings)} buildings")
print(f"   - Dataset shape: {df_train.shape}")

# Sáº¯p xáº¿p theo thá»i gian
df_train = df_train.sort_values(['building_id', 'timestamp']).reset_index(drop=True)

# XÃ¡c Ä‘á»‹nh features
all_features = (
    features_info['continuous_features'] + 
    features_info['time_features'] + 
    features_info['lag_features']
)

# Loáº¡i bá» cÃ¡c features khÃ´ng cÃ³ trong dataset
all_features = [f for f in all_features if f in df_train.columns]
categorical_features = [f for f in features_info['categorical_features'] if f in df_train.columns]

print(f"\nğŸ“Š Features Ä‘Æ°á»£c sá»­ dá»¥ng:")
print(f"   - Continuous/Time/Lag: {len(all_features)}")
print(f"   - Categorical: {len(categorical_features)}")

# Táº¡o X vÃ  y
X = df_train[all_features + categorical_features].copy()
y = df_train[features_info['target']].copy()

# Encode categorical features
label_encoders = {}
for col in categorical_features:
    if col not in X.columns:
        continue
    
    # Äáº£m báº£o lÃ  Series 1D
    col_data = X[col]
    if isinstance(col_data, pd.DataFrame):
        col_data = col_data.iloc[:, 0]
    elif not isinstance(col_data, pd.Series):
        col_data = pd.Series(col_data, index=X.index)
    
    le = LabelEncoder()
    X[col] = le.fit_transform(col_data.astype(str))
    label_encoders[col] = le

print(f"âœ… ÄÃ£ encode {len(label_encoders)} categorical features")

# Loáº¡i bá» duplicate columns (náº¿u cÃ³)
if X.columns.duplicated().any():
    X = X.loc[:, ~X.columns.duplicated()]
    print(f"âœ… ÄÃ£ loáº¡i bá» duplicate columns")

# Äáº£m báº£o táº¥t cáº£ cÃ¡c cá»™t Ä‘á»u lÃ  Series 1D
for col in X.columns:
    col_data = X[col]
    if isinstance(col_data, pd.DataFrame):
        X[col] = col_data.iloc[:, 0]

# ============================================================================
# 3. CHIA TRAIN/TEST SET (THEO THá»œI GIAN)
# ============================================================================

print("\n" + "=" * 80)
print("BÆ¯á»šC 3: CHIA TRAIN/TEST SET")
print("=" * 80)

# Chia theo thá»i gian (80% train, 20% test)
split_idx = int(len(df_train) * 0.8)

X_train = X.iloc[:split_idx]
y_train = y.iloc[:split_idx]
X_test = X.iloc[split_idx:]
y_test = y.iloc[split_idx:]

print(f"âœ… Train set: {X_train.shape[0]} samples")
print(f"âœ… Test set: {X_test.shape[0]} samples")
print(f"\n   Train period: {df_train.iloc[0]['timestamp']} Ä‘áº¿n {df_train.iloc[split_idx-1]['timestamp']}")
print(f"   Test period: {df_train.iloc[split_idx]['timestamp']} Ä‘áº¿n {df_train.iloc[-1]['timestamp']}")

# ============================================================================
# 4. TRAIN XGBOOST MODEL
# ============================================================================

print("\n" + "=" * 80)
print("BÆ¯á»šC 4: TRAIN XGBOOST MODEL")
print("=" * 80)

xgb_model = xgb.XGBRegressor(
    n_estimators=200,
    max_depth=8,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    min_child_weight=3,
    random_state=42,
    n_jobs=-1,
    objective='reg:squarederror',
    eval_metric='rmse'
)

print("Äang training...")
xgb_model.fit(
    X_train, y_train,
    eval_set=[(X_train, y_train), (X_test, y_test)],
    verbose=50
)

# Predictions
y_pred_train = xgb_model.predict(X_train)
y_pred_test = xgb_model.predict(X_test)

# Metrics
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
train_mae = mean_absolute_error(y_train, y_pred_train)
test_mae = mean_absolute_error(y_test, y_pred_test)
train_r2 = r2_score(y_train, y_pred_train)
test_r2 = r2_score(y_test, y_pred_test)
test_mape = mean_absolute_percentage_error(y_test, y_pred_test)

print(f"\nâœ… Model Performance:")
print(f"\nTrain Set:")
print(f"  RMSE: {train_rmse:.2f} kWh")
print(f"  MAE:  {train_mae:.2f} kWh")
print(f"  RÂ²:   {train_r2:.4f}")

print(f"\nTest Set:")
print(f"  RMSE: {test_rmse:.2f} kWh")
print(f"  MAE:  {test_mae:.2f} kWh")
print(f"  RÂ²:   {test_r2:.4f}")
print(f"  MAPE: {test_mape:.2%}")

# ============================================================================
# 5. Táº O WRAPPER CLASS CHO DiCE
# ============================================================================

print("\n" + "=" * 80)
print("BÆ¯á»šC 5: Táº O WRAPPER CLASS CHO DiCE")
print("=" * 80)

class XGBoostWrapper:
    """
    Wrapper class Ä‘á»ƒ tá»± Ä‘á»™ng encode categorical features trÆ°á»›c khi predict
    TÆ°Æ¡ng thÃ­ch vá»›i DiCE (Diverse Counterfactual Explanations)
    """
    def __init__(self, model, label_encoders, categorical_features):
        self.model = model
        self.label_encoders = label_encoders
        self.categorical_features = categorical_features
    
    def predict(self, X):
        """Predict vá»›i tá»± Ä‘á»™ng encode categorical features"""
        # Convert to DataFrame náº¿u lÃ  array hoáº·c Series
        if isinstance(X, np.ndarray):
            # Náº¿u lÃ  array, cáº§n column names
            X = pd.DataFrame(X, columns=self.model.feature_names_in_)
        elif isinstance(X, pd.Series):
            X = X.to_frame().T
        
        X_encoded = X.copy()
        
        # Encode categorical features
        for col in self.categorical_features:
            if col in X_encoded.columns:
                if col in self.label_encoders:
                    le = self.label_encoders[col]
                    # Chuyá»ƒn Ä‘á»•i vá» string vÃ  encode
                    X_encoded[col] = X_encoded[col].astype(str)
                    # Xá»­ lÃ½ cÃ¡c giÃ¡ trá»‹ chÆ°a tháº¥y (unknown values)
                    mask = ~X_encoded[col].isin(le.classes_)
                    unknown_count = int(np.sum(mask.values)) if isinstance(mask, pd.Series) else int(np.sum(mask))
                    if unknown_count > 0:
                        X_encoded.loc[mask, col] = le.classes_[0]
                    X_encoded[col] = le.transform(X_encoded[col])
                else:
                    # Náº¿u khÃ´ng cÃ³ encoder, giá»¯ nguyÃªn (cÃ³ thá»ƒ lÃ  integer rá»“i)
                    if X_encoded[col].dtype == 'object':
                        X_encoded[col] = 0
        
        # Äáº£m báº£o táº¥t cáº£ columns lÃ  numeric
        for col in X_encoded.columns:
            if X_encoded[col].dtype == 'object':
                X_encoded[col] = pd.to_numeric(X_encoded[col], errors='coerce').fillna(0)
        
        # Äáº£m báº£o thá»© tá»± columns Ä‘Ãºng vá»›i model
        if hasattr(self.model, 'feature_names_in_'):
            X_encoded = X_encoded.reindex(columns=self.model.feature_names_in_, fill_value=0)
        
        return self.model.predict(X_encoded)

# Táº¡o wrapped model
xgb_model_wrapped = XGBoostWrapper(
    xgb_model,
    label_encoders,
    categorical_features
)

print("âœ… ÄÃ£ táº¡o XGBoostWrapper cho DiCE")

# Test wrapper
test_pred_wrapped = xgb_model_wrapped.predict(X_test.head(10))
test_pred_original = xgb_model.predict(X_test.head(10))
diff = np.abs(test_pred_wrapped - test_pred_original).max()
print(f"âœ… Test wrapper: Max difference = {diff:.6f} (should be ~0)")

# ============================================================================
# 6. LÆ¯U MODEL VÃ€ THÃ”NG TIN
# ============================================================================

print("\n" + "=" * 80)
print("BÆ¯á»šC 6: LÆ¯U MODEL VÃ€ THÃ”NG TIN")
print("=" * 80)

os.makedirs('output/models', exist_ok=True)

# LÆ°u XGBoost model
model_path = "output/models/xgboost_dice.pkl"
with open(model_path, 'wb') as f:
    pickle.dump(xgb_model, f)
print(f"âœ… ÄÃ£ lÆ°u XGBoost model vÃ o: {model_path}")

# LÆ°u wrapped model
wrapped_model_path = "output/models/xgboost_wrapped_dice.pkl"
with open(wrapped_model_path, 'wb') as f:
    pickle.dump(xgb_model_wrapped, f)
print(f"âœ… ÄÃ£ lÆ°u Wrapped model vÃ o: {wrapped_model_path}")

# LÆ°u label encoders
encoders_path = "output/models/label_encoders_dice.pkl"
with open(encoders_path, 'wb') as f:
    pickle.dump(label_encoders, f)
print(f"âœ… ÄÃ£ lÆ°u Label Encoders vÃ o: {encoders_path}")

# LÆ°u thÃ´ng tin vá» features vÃ  model
model_info = {
    'model_type': 'XGBoost',
    'features_used': all_features + categorical_features,
    'continuous_features': all_features,
    'categorical_features': categorical_features,
    'training_date': datetime.now().isoformat(),
    'train_size': len(X_train),
    'test_size': len(X_test),
    'performance': {
        'train_rmse': float(train_rmse),
        'test_rmse': float(test_rmse),
        'train_mae': float(train_mae),
        'test_mae': float(test_mae),
        'train_r2': float(train_r2),
        'test_r2': float(test_r2),
        'test_mape': float(test_mape)
    },
    'dice_compatible': True,
    'wrapper_class': 'XGBoostWrapper'
}

with open('output/models/model_info_dice.json', 'w') as f:
    json.dump(model_info, f, indent=2, default=str)

print(f"âœ… ÄÃ£ lÆ°u thÃ´ng tin model vÃ o: output/models/model_info_dice.json")

print("\n" + "=" * 80)
print("HOÃ€N THÃ€NH TRAINING!")
print("=" * 80)
print(f"âœ… Model Ä‘Ã£ Ä‘Æ°á»£c train vÃ  lÆ°u")
print(f"ğŸ“Š Test RÂ²: {test_r2:.4f}, Test RMSE: {test_rmse:.2f} kWh")
print(f"âœ… Model Ä‘Ã£ sáºµn sÃ ng cho DiCE integration")
print(f"ğŸ“ Models Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trong: output/models/")
