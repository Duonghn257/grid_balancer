#!/usr/bin/env python3
"""
Script 7: Prediction v·ªõi XGBoost Model
S·ª≠ d·ª•ng XGBoost model ƒë√£ train ƒë·ªÉ d·ª± ƒëo√°n l∆∞·ª£ng ƒëi·ªán ti√™u th·ª•
"""

import pandas as pd
import numpy as np
import warnings
from pathlib import Path
import os
import json
import pickle

warnings.filterwarnings('ignore')

print("=" * 80)
print("PREDICTION V·ªöI XGBOOST MODEL")
print("=" * 80)

# ============================================================================
# 1. LOAD MODEL V√Ä TH√îNG TIN
# ============================================================================

print("\n" + "=" * 80)
print("B∆Ø·ªöC 1: LOAD MODEL")
print("=" * 80)

# Load model info
with open('output/models/model_info_dice.json', 'r') as f:
    model_info = json.load(f)

# Load features info
with open('output/features_info.json', 'r') as f:
    features_info = json.load(f)

# Load wrapped model (t∆∞∆°ng th√≠ch v·ªõi DiCE)
with open('output/models/xgboost_wrapped_dice.pkl', 'rb') as f:
    model = pickle.load(f)

# Load label encoders
with open('output/models/label_encoders_dice.pkl', 'rb') as f:
    label_encoders = pickle.load(f)

print(f"\nüìä Model: {model_info['model_type']}")
print(f"   - Test R¬≤: {model_info['performance']['test_r2']:.4f}")
print(f"   - Test RMSE: {model_info['performance']['test_rmse']:.2f} kWh")
print(f"   - DiCE Compatible: {model_info['dice_compatible']}")

# ============================================================================
# 2. LOAD D·ªÆ LI·ªÜU ƒê·ªÇ PREDICT
# ============================================================================

print("\n" + "=" * 80)
print("B∆Ø·ªöC 2: LOAD D·ªÆ LI·ªÜU")
print("=" * 80)

# Load d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
print("\nüìÇ ƒêang load d·ªØ li·ªáu...")
df = pd.read_parquet("./output/processed_data.parquet")

# Sample m·ªôt s·ªë buildings ƒë·ªÉ predict (ho·∫∑c c√≥ th·ªÉ predict to√†n b·ªô)
np.random.seed(42)
sample_size = min(50, df['building_id'].nunique())
sample_buildings = np.random.choice(
    df['building_id'].unique(), 
    size=sample_size, 
    replace=False
)
df_predict = df[df['building_id'].isin(sample_buildings)].copy()
df_predict = df_predict.sort_values(['building_id', 'timestamp']).reset_index(drop=True)

# L·∫•y test set (20% cu·ªëi)
split_idx = int(len(df_predict) * 0.8)
df_predict = df_predict.iloc[split_idx:].copy()

print(f"‚úÖ Dataset ƒë·ªÉ predict: {df_predict.shape}")
print(f"   - S·ªë buildings: {df_predict['building_id'].nunique()}")
print(f"   - S·ªë timestamps: {df_predict['timestamp'].nunique()}")

# ============================================================================
# 3. CHU·∫®N B·ªä FEATURES
# ============================================================================

print("\n" + "=" * 80)
print("B∆Ø·ªöC 3: CHU·∫®N B·ªä FEATURES")
print("=" * 80)

# X√°c ƒë·ªãnh features
all_features = model_info['continuous_features']
categorical_features = model_info['categorical_features']

# L·∫•y features t·ª´ d·ªØ li·ªáu
X_predict = df_predict[all_features + categorical_features].copy()

# Lo·∫°i b·ªè duplicate columns
if X_predict.columns.duplicated().any():
    X_predict = X_predict.loc[:, ~X_predict.columns.duplicated()]

# ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c c·ªôt ƒë·ªÅu l√† Series 1D
for col in X_predict.columns:
    col_data = X_predict[col]
    if isinstance(col_data, pd.DataFrame):
        X_predict[col] = col_data.iloc[:, 0]

print(f"‚úÖ Features shape: {X_predict.shape}")

# ============================================================================
# 4. PREDICT
# ============================================================================

print("\n" + "=" * 80)
print("B∆Ø·ªöC 4: PREDICT")
print("=" * 80)

print("\nüìä ƒêang th·ª±c hi·ªán prediction...")
predictions = model.predict(X_predict)

print(f"‚úÖ ƒê√£ predict {len(predictions)} samples")
print(f"   - Min prediction: {predictions.min():.2f} kWh")
print(f"   - Max prediction: {predictions.max():.2f} kWh")
print(f"   - Mean prediction: {predictions.mean():.2f} kWh")

# ============================================================================
# 5. T·∫†O K·∫æT QU·∫¢
# ============================================================================

print("\n" + "=" * 80)
print("B∆Ø·ªöC 5: T·∫†O K·∫æT QU·∫¢")
print("=" * 80)

# T·∫°o DataFrame k·∫øt qu·∫£
results_df = pd.DataFrame({
    'building_id': df_predict['building_id'].values,
    'timestamp': df_predict['timestamp'].values,
    'predicted_consumption': predictions
})

# Th√™m th√¥ng tin building
if 'primaryspaceusage' in df_predict.columns:
    results_df = pd.merge(
        results_df,
        df_predict[['building_id', 'primaryspaceusage', 'sqm', 'site_id']].drop_duplicates(),
        on='building_id',
        how='left'
    )

# Th√™m actual values n·∫øu c√≥ (ƒë·ªÉ so s√°nh)
if features_info['target'] in df_predict.columns:
    results_df['actual_consumption'] = df_predict[features_info['target']].values
    results_df['error'] = results_df['actual_consumption'] - results_df['predicted_consumption']
    results_df['absolute_error'] = np.abs(results_df['error'])
    results_df['percentage_error'] = (results_df['absolute_error'] / results_df['actual_consumption'] * 100).round(2)
    
    # T√≠nh metrics
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    
    rmse = np.sqrt(mean_squared_error(results_df['actual_consumption'], results_df['predicted_consumption']))
    mae = mean_absolute_error(results_df['actual_consumption'], results_df['predicted_consumption'])
    r2 = r2_score(results_df['actual_consumption'], results_df['predicted_consumption'])
    
    print(f"\nüìä Metrics:")
    print(f"   - RMSE: {rmse:.2f} kWh")
    print(f"   - MAE: {mae:.2f} kWh")
    print(f"   - R¬≤: {r2:.4f}")

# Hi·ªÉn th·ªã sample k·∫øt qu·∫£
print(f"\nüìã Sample k·∫øt qu·∫£ (10 d√≤ng ƒë·∫ßu):")
print(results_df.head(10).to_string())

# ============================================================================
# 6. L∆ØU K·∫æT QU·∫¢
# ============================================================================

print("\n" + "=" * 80)
print("B∆Ø·ªöC 6: L∆ØU K·∫æT QU·∫¢")
print("=" * 80)

output_path = 'output/predictions_xgboost.csv'
results_df.to_csv(output_path, index=False)
print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {output_path}")

# L∆∞u summary
summary = {
    'model_type': model_info['model_type'],
    'total_predictions': len(results_df),
    'num_buildings': results_df['building_id'].nunique(),
    'num_timestamps': results_df['timestamp'].nunique(),
    'date_range': {
        'start': str(results_df['timestamp'].min()),
        'end': str(results_df['timestamp'].max())
    }
}

if 'actual_consumption' in results_df.columns:
    summary['metrics'] = {
        'rmse': float(rmse),
        'mae': float(mae),
        'r2': float(r2)
    }

summary_path = 'output/predictions_xgboost_summary.json'
with open(summary_path, 'w') as f:
    json.dump(summary, f, indent=2, default=str)

print(f"‚úÖ ƒê√£ l∆∞u summary v√†o: {summary_path}")

print("\n" + "=" * 80)
print("HO√ÄN TH√ÄNH PREDICTION!")
print("=" * 80)
print(f"‚úÖ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u trong: {output_path}")
